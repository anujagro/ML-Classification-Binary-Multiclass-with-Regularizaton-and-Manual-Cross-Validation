{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Assignment 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Data Munging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the training and testing Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>909410</td>\n",
       "      <td>B</td>\n",
       "      <td>14.02</td>\n",
       "      <td>15.66</td>\n",
       "      <td>89.59</td>\n",
       "      <td>606.5</td>\n",
       "      <td>0.07966</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>0.02087</td>\n",
       "      <td>0.02652</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>19.31</td>\n",
       "      <td>96.53</td>\n",
       "      <td>688.9</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.06260</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.06710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8912284</td>\n",
       "      <td>B</td>\n",
       "      <td>12.89</td>\n",
       "      <td>15.70</td>\n",
       "      <td>84.08</td>\n",
       "      <td>516.6</td>\n",
       "      <td>0.07818</td>\n",
       "      <td>0.09580</td>\n",
       "      <td>0.11150</td>\n",
       "      <td>0.03390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.90</td>\n",
       "      <td>19.69</td>\n",
       "      <td>92.12</td>\n",
       "      <td>595.6</td>\n",
       "      <td>0.09926</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>0.33440</td>\n",
       "      <td>0.10170</td>\n",
       "      <td>0.1999</td>\n",
       "      <td>0.07127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90317302</td>\n",
       "      <td>B</td>\n",
       "      <td>10.26</td>\n",
       "      <td>12.22</td>\n",
       "      <td>65.75</td>\n",
       "      <td>321.6</td>\n",
       "      <td>0.09996</td>\n",
       "      <td>0.07542</td>\n",
       "      <td>0.01923</td>\n",
       "      <td>0.01968</td>\n",
       "      <td>...</td>\n",
       "      <td>11.38</td>\n",
       "      <td>15.65</td>\n",
       "      <td>73.23</td>\n",
       "      <td>394.5</td>\n",
       "      <td>0.13430</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.08615</td>\n",
       "      <td>0.06696</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>0.07722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>914102</td>\n",
       "      <td>B</td>\n",
       "      <td>13.16</td>\n",
       "      <td>20.54</td>\n",
       "      <td>84.06</td>\n",
       "      <td>538.7</td>\n",
       "      <td>0.07335</td>\n",
       "      <td>0.05275</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>0.01256</td>\n",
       "      <td>...</td>\n",
       "      <td>14.50</td>\n",
       "      <td>28.46</td>\n",
       "      <td>95.29</td>\n",
       "      <td>648.3</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.07698</td>\n",
       "      <td>0.04195</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.07429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID Diagnosis     f1     f2      f3      f4       f5       f6  \\\n",
       "0      909410         B  14.02  15.66   89.59   606.5  0.07966  0.05581   \n",
       "1    84358402         M  20.29  14.34  135.10  1297.0  0.10030  0.13280   \n",
       "2     8912284         B  12.89  15.70   84.08   516.6  0.07818  0.09580   \n",
       "3    90317302         B  10.26  12.22   65.75   321.6  0.09996  0.07542   \n",
       "4      914102         B  13.16  20.54   84.06   538.7  0.07335  0.05275   \n",
       "\n",
       "        f7       f8   ...       f21    f22     f23     f24      f25     f26  \\\n",
       "0  0.02087  0.02652   ...     14.91  19.31   96.53   688.9  0.10340  0.1017   \n",
       "1  0.19800  0.10430   ...     22.54  16.67  152.20  1575.0  0.13740  0.2050   \n",
       "2  0.11150  0.03390   ...     13.90  19.69   92.12   595.6  0.09926  0.2317   \n",
       "3  0.01923  0.01968   ...     11.38  15.65   73.23   394.5  0.13430  0.1650   \n",
       "4  0.01800  0.01256   ...     14.50  28.46   95.29   648.3  0.11180  0.1646   \n",
       "\n",
       "       f27      f28     f29      f30  \n",
       "0  0.06260  0.08216  0.2136  0.06710  \n",
       "1  0.40000  0.16250  0.2364  0.07678  \n",
       "2  0.33440  0.10170  0.1999  0.07127  \n",
       "3  0.08615  0.06696  0.2937  0.07722  \n",
       "4  0.07698  0.04195  0.2687  0.07429  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test_wbcd.csv\")\n",
    "train = pd.read_csv(\"train_wbcd.csv\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>894047</td>\n",
       "      <td>B</td>\n",
       "      <td>8.597</td>\n",
       "      <td>18.60</td>\n",
       "      <td>54.09</td>\n",
       "      <td>221.2</td>\n",
       "      <td>0.10740</td>\n",
       "      <td>0.05847</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.952</td>\n",
       "      <td>22.44</td>\n",
       "      <td>56.65</td>\n",
       "      <td>240.1</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.07767</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>0.08116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892189</td>\n",
       "      <td>M</td>\n",
       "      <td>11.760</td>\n",
       "      <td>18.14</td>\n",
       "      <td>75.00</td>\n",
       "      <td>431.1</td>\n",
       "      <td>0.09968</td>\n",
       "      <td>0.05914</td>\n",
       "      <td>0.02685</td>\n",
       "      <td>0.03515</td>\n",
       "      <td>...</td>\n",
       "      <td>13.360</td>\n",
       "      <td>23.39</td>\n",
       "      <td>85.10</td>\n",
       "      <td>553.6</td>\n",
       "      <td>0.1137</td>\n",
       "      <td>0.07974</td>\n",
       "      <td>0.06120</td>\n",
       "      <td>0.07160</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8810528</td>\n",
       "      <td>B</td>\n",
       "      <td>11.840</td>\n",
       "      <td>18.94</td>\n",
       "      <td>75.51</td>\n",
       "      <td>428.0</td>\n",
       "      <td>0.08871</td>\n",
       "      <td>0.06900</td>\n",
       "      <td>0.02669</td>\n",
       "      <td>0.01393</td>\n",
       "      <td>...</td>\n",
       "      <td>13.300</td>\n",
       "      <td>24.99</td>\n",
       "      <td>85.22</td>\n",
       "      <td>546.3</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.18800</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.06913</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>0.07993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>905978</td>\n",
       "      <td>B</td>\n",
       "      <td>9.405</td>\n",
       "      <td>21.70</td>\n",
       "      <td>59.60</td>\n",
       "      <td>271.2</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.06159</td>\n",
       "      <td>0.02047</td>\n",
       "      <td>0.01257</td>\n",
       "      <td>...</td>\n",
       "      <td>10.850</td>\n",
       "      <td>31.24</td>\n",
       "      <td>68.73</td>\n",
       "      <td>359.4</td>\n",
       "      <td>0.1526</td>\n",
       "      <td>0.11930</td>\n",
       "      <td>0.06141</td>\n",
       "      <td>0.03770</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>0.08304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>871001502</td>\n",
       "      <td>B</td>\n",
       "      <td>8.219</td>\n",
       "      <td>20.70</td>\n",
       "      <td>53.27</td>\n",
       "      <td>203.9</td>\n",
       "      <td>0.09405</td>\n",
       "      <td>0.13050</td>\n",
       "      <td>0.13210</td>\n",
       "      <td>0.02168</td>\n",
       "      <td>...</td>\n",
       "      <td>9.092</td>\n",
       "      <td>29.72</td>\n",
       "      <td>58.08</td>\n",
       "      <td>249.8</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>0.53810</td>\n",
       "      <td>0.07879</td>\n",
       "      <td>0.3322</td>\n",
       "      <td>0.14860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID Diagnosis      f1     f2     f3     f4       f5       f6  \\\n",
       "0      894047         B   8.597  18.60  54.09  221.2  0.10740  0.05847   \n",
       "1      892189         M  11.760  18.14  75.00  431.1  0.09968  0.05914   \n",
       "2     8810528         B  11.840  18.94  75.51  428.0  0.08871  0.06900   \n",
       "3      905978         B   9.405  21.70  59.60  271.2  0.10440  0.06159   \n",
       "4   871001502         B   8.219  20.70  53.27  203.9  0.09405  0.13050   \n",
       "\n",
       "        f7       f8   ...        f21    f22    f23    f24     f25      f26  \\\n",
       "0  0.00000  0.00000   ...      8.952  22.44  56.65  240.1  0.1347  0.07767   \n",
       "1  0.02685  0.03515   ...     13.360  23.39  85.10  553.6  0.1137  0.07974   \n",
       "2  0.02669  0.01393   ...     13.300  24.99  85.22  546.3  0.1280  0.18800   \n",
       "3  0.02047  0.01257   ...     10.850  31.24  68.73  359.4  0.1526  0.11930   \n",
       "4  0.13210  0.02168   ...      9.092  29.72  58.08  249.8  0.1630  0.43100   \n",
       "\n",
       "       f27      f28     f29      f30  \n",
       "0  0.00000  0.00000  0.3142  0.08116  \n",
       "1  0.06120  0.07160  0.1978  0.06915  \n",
       "2  0.14710  0.06913  0.2535  0.07993  \n",
       "3  0.06141  0.03770  0.2872  0.08304  \n",
       "4  0.53810  0.07879  0.3322  0.14860  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbcd = [train,test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 32), (20, 32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns\n",
    "# No of Features/Columns in DataSet: = 32\n",
    "len(train.columns), len(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Features in test: \n",
      " {'B': 14, 'M': 6}\n",
      "\n",
      "\n",
      "No of Features in train: \n",
      " {'B': 58, 'M': 42}\n"
     ]
    }
   ],
   "source": [
    "# No of Features Values for B and M in Test Dataset\n",
    "\n",
    "print(\"No of Features in test:\", \"\\n\",test['Diagnosis'].value_counts().to_dict())\n",
    "print(\"\\n\")\n",
    "print(\"No of Features in train:\", \"\\n\",train['Diagnosis'].value_counts().to_dict())\n",
    "\n",
    "# Expressing as % of Total:\n",
    "\n",
    "\n",
    "#print(\"No of Features in test:\", \"\\n\",test['Diagnosis'].value_counts() / test['Diagnosis'].count .to_dict())\n",
    "#print(\"\\n\")\n",
    "#print(\"No of Features in train:\", \"\\n\",train['Diagnosis'].value_counts().to_dict())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Patient_ID    0\n",
       " Diagnosis     0\n",
       " f1            0\n",
       " f2            0\n",
       " f3            0\n",
       " f4            0\n",
       " f5            0\n",
       " f6            0\n",
       " f7            0\n",
       " f8            0\n",
       " f9            0\n",
       " f10           0\n",
       " f11           0\n",
       " f12           0\n",
       " f13           0\n",
       " f14           0\n",
       " f15           0\n",
       " f16           0\n",
       " f17           0\n",
       " f18           0\n",
       " f19           0\n",
       " f20           0\n",
       " f21           2\n",
       " f22           0\n",
       " f23           0\n",
       " f24           0\n",
       " f25           0\n",
       " f26           0\n",
       " f27           0\n",
       " f28           0\n",
       " f29           0\n",
       " f30           0\n",
       " dtype: int64, Patient_ID    0\n",
       " Diagnosis     0\n",
       " f1            0\n",
       " f2            0\n",
       " f3            0\n",
       " f4            0\n",
       " f5            0\n",
       " f6            0\n",
       " f7            0\n",
       " f8            0\n",
       " f9            0\n",
       " f10           0\n",
       " f11           0\n",
       " f12           0\n",
       " f13           0\n",
       " f14           0\n",
       " f15           0\n",
       " f16           0\n",
       " f17           0\n",
       " f18           0\n",
       " f19           0\n",
       " f20           0\n",
       " f21           1\n",
       " f22           0\n",
       " f23           0\n",
       " f24           0\n",
       " f25           0\n",
       " f26           0\n",
       " f27           0\n",
       " f28           0\n",
       " f29           0\n",
       " f30           0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHecking for Null values in each column in test dataset:\n",
    "train.isna().sum(), test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No missing Values in testing Dataset. \n",
    "# Checking for Zero Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Patient_ID    0\n",
       " Diagnosis     0\n",
       " f1            0\n",
       " f2            0\n",
       " f3            0\n",
       " f4            0\n",
       " f5            0\n",
       " f6            0\n",
       " f7            6\n",
       " f8            6\n",
       " f9            0\n",
       " f10           0\n",
       " f11           0\n",
       " f12           0\n",
       " f13           0\n",
       " f14           0\n",
       " f15           0\n",
       " f16           0\n",
       " f17           6\n",
       " f18           6\n",
       " f19           0\n",
       " f20           0\n",
       " f21           0\n",
       " f22           0\n",
       " f23           0\n",
       " f24           0\n",
       " f25           0\n",
       " f26           0\n",
       " f27           6\n",
       " f28           6\n",
       " f29           0\n",
       " f30           0\n",
       " dtype: int64, Patient_ID    0\n",
       " Diagnosis     0\n",
       " f1            0\n",
       " f2            0\n",
       " f3            0\n",
       " f4            0\n",
       " f5            0\n",
       " f6            0\n",
       " f7            1\n",
       " f8            1\n",
       " f9            0\n",
       " f10           0\n",
       " f11           0\n",
       " f12           0\n",
       " f13           0\n",
       " f14           0\n",
       " f15           0\n",
       " f16           0\n",
       " f17           1\n",
       " f18           1\n",
       " f19           0\n",
       " f20           0\n",
       " f21           0\n",
       " f22           0\n",
       " f23           0\n",
       " f24           0\n",
       " f25           0\n",
       " f26           0\n",
       " f27           1\n",
       " f28           1\n",
       " f29           0\n",
       " f30           0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.eq(0).sum(), test.eq(0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above output we can see that: \n",
    "#feature f7, f8, f17, f18, f27 and f28 each have 6 zero value each - Train Dataset\n",
    "#feature f7, f8, f17, f18, f27 and f28 each have 1 zero value each - Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.160791e+07</td>\n",
       "      <td>14.225920</td>\n",
       "      <td>19.207900</td>\n",
       "      <td>92.722600</td>\n",
       "      <td>666.375000</td>\n",
       "      <td>0.095696</td>\n",
       "      <td>0.106129</td>\n",
       "      <td>0.090364</td>\n",
       "      <td>0.049346</td>\n",
       "      <td>0.179893</td>\n",
       "      <td>...</td>\n",
       "      <td>16.486765</td>\n",
       "      <td>25.380800</td>\n",
       "      <td>108.925200</td>\n",
       "      <td>909.191000</td>\n",
       "      <td>0.132563</td>\n",
       "      <td>0.265144</td>\n",
       "      <td>0.278176</td>\n",
       "      <td>0.117597</td>\n",
       "      <td>0.289196</td>\n",
       "      <td>0.083999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.737600e+07</td>\n",
       "      <td>3.729963</td>\n",
       "      <td>4.732476</td>\n",
       "      <td>25.924925</td>\n",
       "      <td>366.768846</td>\n",
       "      <td>0.013496</td>\n",
       "      <td>0.057694</td>\n",
       "      <td>0.084449</td>\n",
       "      <td>0.042066</td>\n",
       "      <td>0.027482</td>\n",
       "      <td>...</td>\n",
       "      <td>5.250147</td>\n",
       "      <td>6.689072</td>\n",
       "      <td>36.432902</td>\n",
       "      <td>597.843396</td>\n",
       "      <td>0.022108</td>\n",
       "      <td>0.161632</td>\n",
       "      <td>0.210617</td>\n",
       "      <td>0.075227</td>\n",
       "      <td>0.058586</td>\n",
       "      <td>0.014823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>7.729000</td>\n",
       "      <td>10.820000</td>\n",
       "      <td>47.980000</td>\n",
       "      <td>178.800000</td>\n",
       "      <td>0.068830</td>\n",
       "      <td>0.023440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.077000</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>57.170000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156600</td>\n",
       "      <td>0.059050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.650350e+05</td>\n",
       "      <td>11.880000</td>\n",
       "      <td>15.607500</td>\n",
       "      <td>75.667500</td>\n",
       "      <td>430.825000</td>\n",
       "      <td>0.084645</td>\n",
       "      <td>0.062065</td>\n",
       "      <td>0.025070</td>\n",
       "      <td>0.019017</td>\n",
       "      <td>0.161700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.052500</td>\n",
       "      <td>19.510000</td>\n",
       "      <td>84.055000</td>\n",
       "      <td>514.925000</td>\n",
       "      <td>0.119275</td>\n",
       "      <td>0.156575</td>\n",
       "      <td>0.093762</td>\n",
       "      <td>0.060362</td>\n",
       "      <td>0.246875</td>\n",
       "      <td>0.073960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.013015e+05</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>18.805000</td>\n",
       "      <td>87.355000</td>\n",
       "      <td>572.050000</td>\n",
       "      <td>0.094985</td>\n",
       "      <td>0.096485</td>\n",
       "      <td>0.066145</td>\n",
       "      <td>0.032565</td>\n",
       "      <td>0.179700</td>\n",
       "      <td>...</td>\n",
       "      <td>15.315000</td>\n",
       "      <td>25.670000</td>\n",
       "      <td>98.245000</td>\n",
       "      <td>727.100000</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.237700</td>\n",
       "      <td>0.256650</td>\n",
       "      <td>0.104250</td>\n",
       "      <td>0.279600</td>\n",
       "      <td>0.081660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.821689e+06</td>\n",
       "      <td>15.707500</td>\n",
       "      <td>21.917500</td>\n",
       "      <td>103.650000</td>\n",
       "      <td>768.325000</td>\n",
       "      <td>0.103825</td>\n",
       "      <td>0.130025</td>\n",
       "      <td>0.135875</td>\n",
       "      <td>0.076825</td>\n",
       "      <td>0.193400</td>\n",
       "      <td>...</td>\n",
       "      <td>19.147500</td>\n",
       "      <td>30.870000</td>\n",
       "      <td>125.450000</td>\n",
       "      <td>1110.250000</td>\n",
       "      <td>0.147875</td>\n",
       "      <td>0.357050</td>\n",
       "      <td>0.400900</td>\n",
       "      <td>0.173950</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>0.093808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.197970e+07</td>\n",
       "      <td>25.220000</td>\n",
       "      <td>32.470000</td>\n",
       "      <td>171.500000</td>\n",
       "      <td>1878.000000</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.311400</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.184500</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>...</td>\n",
       "      <td>31.010000</td>\n",
       "      <td>45.410000</td>\n",
       "      <td>211.700000</td>\n",
       "      <td>2944.000000</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.758400</td>\n",
       "      <td>0.960800</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.475300</td>\n",
       "      <td>0.128400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Patient_ID          f1          f2          f3           f4  \\\n",
       "count  1.000000e+02  100.000000  100.000000  100.000000   100.000000   \n",
       "mean   1.160791e+07   14.225920   19.207900   92.722600   666.375000   \n",
       "std    2.737600e+07    3.729963    4.732476   25.924925   366.768846   \n",
       "min    8.670000e+03    7.729000   10.820000   47.980000   178.800000   \n",
       "25%    8.650350e+05   11.880000   15.607500   75.667500   430.825000   \n",
       "50%    9.013015e+05   13.600000   18.805000   87.355000   572.050000   \n",
       "75%    2.821689e+06   15.707500   21.917500  103.650000   768.325000   \n",
       "max    9.197970e+07   25.220000   32.470000  171.500000  1878.000000   \n",
       "\n",
       "               f5          f6          f7          f8          f9     ...      \\\n",
       "count  100.000000  100.000000  100.000000  100.000000  100.000000     ...       \n",
       "mean     0.095696    0.106129    0.090364    0.049346    0.179893     ...       \n",
       "std      0.013496    0.057694    0.084449    0.042066    0.027482     ...       \n",
       "min      0.068830    0.023440    0.000000    0.000000    0.106000     ...       \n",
       "25%      0.084645    0.062065    0.025070    0.019017    0.161700     ...       \n",
       "50%      0.094985    0.096485    0.066145    0.032565    0.179700     ...       \n",
       "75%      0.103825    0.130025    0.135875    0.076825    0.193400     ...       \n",
       "max      0.132600    0.311400    0.426400    0.184500    0.255600     ...       \n",
       "\n",
       "             f21         f22         f23          f24         f25         f26  \\\n",
       "count  98.000000  100.000000  100.000000   100.000000  100.000000  100.000000   \n",
       "mean   16.486765   25.380800  108.925200   909.191000    0.132563    0.265144   \n",
       "std     5.250147    6.689072   36.432902   597.843396    0.022108    0.161632   \n",
       "min     9.077000   14.100000   57.170000   248.000000    0.071170    0.027290   \n",
       "25%    13.052500   19.510000   84.055000   514.925000    0.119275    0.156575   \n",
       "50%    15.315000   25.670000   98.245000   727.100000    0.134300    0.237700   \n",
       "75%    19.147500   30.870000  125.450000  1110.250000    0.147875    0.357050   \n",
       "max    31.010000   45.410000  211.700000  2944.000000    0.187800    0.758400   \n",
       "\n",
       "              f27         f28         f29         f30  \n",
       "count  100.000000  100.000000  100.000000  100.000000  \n",
       "mean     0.278176    0.117597    0.289196    0.083999  \n",
       "std      0.210617    0.075227    0.058586    0.014823  \n",
       "min      0.000000    0.000000    0.156600    0.059050  \n",
       "25%      0.093762    0.060362    0.246875    0.073960  \n",
       "50%      0.256650    0.104250    0.279600    0.081660  \n",
       "75%      0.400900    0.173950    0.320600    0.093808  \n",
       "max      0.960800    0.291000    0.475300    0.128400  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doing some EDA on all the features:\n",
    "\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Patient_ID': 104798968.6,\n",
       " 'f1': 13.267300000000002,\n",
       " 'f2': 20.8295,\n",
       " 'f3': 86.425,\n",
       " 'f4': 608.79,\n",
       " 'f5': 0.09692150000000001,\n",
       " 'f6': 0.10302800000000001,\n",
       " 'f7': 0.08280999999999998,\n",
       " 'f8': 0.041847499999999996,\n",
       " 'f9': 0.18865,\n",
       " 'f10': 0.06598250000000001,\n",
       " 'f11': 0.45153499999999996,\n",
       " 'f12': 1.3734399999999998,\n",
       " 'f13': 3.1300999999999997,\n",
       " 'f14': 52.98449999999999,\n",
       " 'f15': 0.007996399999999999,\n",
       " 'f16': 0.026536499999999998,\n",
       " 'f17': 0.028184899999999995,\n",
       " 'f18': 0.010051099999999999,\n",
       " 'f19': 0.022621999999999996,\n",
       " 'f20': 0.004965750000000001,\n",
       " 'f21': 15.574578947368423,\n",
       " 'f22': 27.935000000000002,\n",
       " 'f23': 102.66799999999998,\n",
       " 'f24': 865.9350000000002,\n",
       " 'f25': 0.13654499999999997,\n",
       " 'f26': 0.259443,\n",
       " 'f27': 0.2613675,\n",
       " 'f28': 0.100253,\n",
       " 'f29': 0.31510999999999995,\n",
       " 'f30': 0.08921899999999999}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from the above output we can see that the mean and median, and they look quite close\n",
    "# Using the Mean to fill out the zero values:\n",
    "\n",
    "# Calculating the mean first\n",
    "\n",
    "mean_values_train = train.mean().to_dict()\n",
    "mean_values_train\n",
    "\n",
    "mean_values_test = test.mean().to_dict()\n",
    "mean_values_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Patient_ID    0\n",
       "Diagnosis     0\n",
       "f1            0\n",
       "f2            0\n",
       "f3            0\n",
       "f4            0\n",
       "f5            0\n",
       "f6            0\n",
       "f7            6\n",
       "f8            6\n",
       "f9            0\n",
       "f10           0\n",
       "f11           0\n",
       "f12           0\n",
       "f13           0\n",
       "f14           0\n",
       "f15           0\n",
       "f16           0\n",
       "f17           6\n",
       "f18           6\n",
       "f19           0\n",
       "f20           0\n",
       "f21           2\n",
       "f22           0\n",
       "f23           0\n",
       "f24           0\n",
       "f25           0\n",
       "f26           0\n",
       "f27           6\n",
       "f28           6\n",
       "f29           0\n",
       "f30           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filling the mean in lieu of the zero value:\n",
    "    # Here we will use the fillna method for convenince, so first will replace all zeros with nan (nulls) and then use fillna()\n",
    "\n",
    "train[train == 0] = np.nan    \n",
    "test[test == 0] = np.nan\n",
    "\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Null values using the fillna method:\n",
    "train = train.fillna(value = mean_values_train)\n",
    "test = test.fillna(value = mean_values_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Patient_ID    0\n",
       "Diagnosis     0\n",
       "f1            0\n",
       "f2            0\n",
       "f3            0\n",
       "f4            0\n",
       "f5            0\n",
       "f6            0\n",
       "f7            0\n",
       "f8            0\n",
       "f9            0\n",
       "f10           0\n",
       "f11           0\n",
       "f12           0\n",
       "f13           0\n",
       "f14           0\n",
       "f15           0\n",
       "f16           0\n",
       "f17           0\n",
       "f18           0\n",
       "f19           0\n",
       "f20           0\n",
       "f21           0\n",
       "f22           0\n",
       "f23           0\n",
       "f24           0\n",
       "f25           0\n",
       "f26           0\n",
       "f27           0\n",
       "f28           0\n",
       "f29           0\n",
       "f30           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Again if there are any Null values:\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the testing and training datasets: Using Standardised Z Scores:\n",
    "#Normalising only the columns f1 - f30 since other 2 are not numeric columns\n",
    "\n",
    "train_normalise = train.drop(['Patient_ID','Diagnosis'], axis = 1)\n",
    "\n",
    "test_normalise = test.drop(['Patient_ID','Diagnosis'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.02</td>\n",
       "      <td>15.66</td>\n",
       "      <td>89.59</td>\n",
       "      <td>606.5</td>\n",
       "      <td>0.07966</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>0.02087</td>\n",
       "      <td>0.02652</td>\n",
       "      <td>0.1589</td>\n",
       "      <td>0.05586</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>19.31</td>\n",
       "      <td>96.53</td>\n",
       "      <td>688.9</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.06260</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.06710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.89</td>\n",
       "      <td>15.70</td>\n",
       "      <td>84.08</td>\n",
       "      <td>516.6</td>\n",
       "      <td>0.07818</td>\n",
       "      <td>0.09580</td>\n",
       "      <td>0.11150</td>\n",
       "      <td>0.03390</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.05935</td>\n",
       "      <td>...</td>\n",
       "      <td>13.90</td>\n",
       "      <td>19.69</td>\n",
       "      <td>92.12</td>\n",
       "      <td>595.6</td>\n",
       "      <td>0.09926</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>0.33440</td>\n",
       "      <td>0.10170</td>\n",
       "      <td>0.1999</td>\n",
       "      <td>0.07127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.26</td>\n",
       "      <td>12.22</td>\n",
       "      <td>65.75</td>\n",
       "      <td>321.6</td>\n",
       "      <td>0.09996</td>\n",
       "      <td>0.07542</td>\n",
       "      <td>0.01923</td>\n",
       "      <td>0.01968</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.06569</td>\n",
       "      <td>...</td>\n",
       "      <td>11.38</td>\n",
       "      <td>15.65</td>\n",
       "      <td>73.23</td>\n",
       "      <td>394.5</td>\n",
       "      <td>0.13430</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.08615</td>\n",
       "      <td>0.06696</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>0.07722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.16</td>\n",
       "      <td>20.54</td>\n",
       "      <td>84.06</td>\n",
       "      <td>538.7</td>\n",
       "      <td>0.07335</td>\n",
       "      <td>0.05275</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>0.01256</td>\n",
       "      <td>0.1713</td>\n",
       "      <td>0.05888</td>\n",
       "      <td>...</td>\n",
       "      <td>14.50</td>\n",
       "      <td>28.46</td>\n",
       "      <td>95.29</td>\n",
       "      <td>648.3</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.07698</td>\n",
       "      <td>0.04195</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.07429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      f1     f2      f3      f4       f5       f6       f7       f8      f9  \\\n",
       "0  14.02  15.66   89.59   606.5  0.07966  0.05581  0.02087  0.02652  0.1589   \n",
       "1  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
       "2  12.89  15.70   84.08   516.6  0.07818  0.09580  0.11150  0.03390  0.1432   \n",
       "3  10.26  12.22   65.75   321.6  0.09996  0.07542  0.01923  0.01968  0.1800   \n",
       "4  13.16  20.54   84.06   538.7  0.07335  0.05275  0.01800  0.01256  0.1713   \n",
       "\n",
       "       f10   ...       f21    f22     f23     f24      f25     f26      f27  \\\n",
       "0  0.05586   ...     14.91  19.31   96.53   688.9  0.10340  0.1017  0.06260   \n",
       "1  0.05883   ...     22.54  16.67  152.20  1575.0  0.13740  0.2050  0.40000   \n",
       "2  0.05935   ...     13.90  19.69   92.12   595.6  0.09926  0.2317  0.33440   \n",
       "3  0.06569   ...     11.38  15.65   73.23   394.5  0.13430  0.1650  0.08615   \n",
       "4  0.05888   ...     14.50  28.46   95.29   648.3  0.11180  0.1646  0.07698   \n",
       "\n",
       "       f28     f29      f30  \n",
       "0  0.08216  0.2136  0.06710  \n",
       "1  0.16250  0.2364  0.07678  \n",
       "2  0.10170  0.1999  0.07127  \n",
       "3  0.06696  0.2937  0.07722  \n",
       "4  0.04195  0.2687  0.07429  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_normalise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.055485</td>\n",
       "      <td>-0.753469</td>\n",
       "      <td>-0.121442</td>\n",
       "      <td>-0.164072</td>\n",
       "      <td>-1.194152</td>\n",
       "      <td>-0.876575</td>\n",
       "      <td>-0.926301</td>\n",
       "      <td>-0.645289</td>\n",
       "      <td>-0.767734</td>\n",
       "      <td>-1.128128</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.304937</td>\n",
       "      <td>-0.912142</td>\n",
       "      <td>-0.341934</td>\n",
       "      <td>-0.370332</td>\n",
       "      <td>-1.325803</td>\n",
       "      <td>-1.016305</td>\n",
       "      <td>-1.176212</td>\n",
       "      <td>-0.618312</td>\n",
       "      <td>-1.296842</td>\n",
       "      <td>-1.145820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.633965</td>\n",
       "      <td>-1.033798</td>\n",
       "      <td>1.642855</td>\n",
       "      <td>1.728069</td>\n",
       "      <td>0.342875</td>\n",
       "      <td>0.464608</td>\n",
       "      <td>1.263840</td>\n",
       "      <td>1.301066</td>\n",
       "      <td>0.036827</td>\n",
       "      <td>-0.644680</td>\n",
       "      <td>...</td>\n",
       "      <td>1.170658</td>\n",
       "      <td>-1.308804</td>\n",
       "      <td>1.193778</td>\n",
       "      <td>1.119295</td>\n",
       "      <td>0.219872</td>\n",
       "      <td>-0.373979</td>\n",
       "      <td>0.532401</td>\n",
       "      <td>0.550714</td>\n",
       "      <td>-0.905710</td>\n",
       "      <td>-0.489469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.359963</td>\n",
       "      <td>-0.744974</td>\n",
       "      <td>-0.335050</td>\n",
       "      <td>-0.410421</td>\n",
       "      <td>-1.304365</td>\n",
       "      <td>-0.179940</td>\n",
       "      <td>0.194302</td>\n",
       "      <td>-0.460613</td>\n",
       "      <td>-1.341897</td>\n",
       "      <td>-0.560035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.500265</td>\n",
       "      <td>-0.855047</td>\n",
       "      <td>-0.463588</td>\n",
       "      <td>-0.527180</td>\n",
       "      <td>-1.514012</td>\n",
       "      <td>-0.207956</td>\n",
       "      <td>0.200199</td>\n",
       "      <td>-0.333986</td>\n",
       "      <td>-1.531864</td>\n",
       "      <td>-0.863074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.068616</td>\n",
       "      <td>-1.484023</td>\n",
       "      <td>-1.045653</td>\n",
       "      <td>-0.944769</td>\n",
       "      <td>0.317555</td>\n",
       "      <td>-0.534964</td>\n",
       "      <td>-0.946579</td>\n",
       "      <td>-0.816452</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>0.471973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987617</td>\n",
       "      <td>-1.462060</td>\n",
       "      <td>-0.984688</td>\n",
       "      <td>-0.865250</td>\n",
       "      <td>0.078943</td>\n",
       "      <td>-0.622702</td>\n",
       "      <td>-1.056954</td>\n",
       "      <td>-0.839487</td>\n",
       "      <td>0.077266</td>\n",
       "      <td>-0.459635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.287212</td>\n",
       "      <td>0.282899</td>\n",
       "      <td>-0.335825</td>\n",
       "      <td>-0.349861</td>\n",
       "      <td>-1.664048</td>\n",
       "      <td>-0.929881</td>\n",
       "      <td>-0.961787</td>\n",
       "      <td>-0.994622</td>\n",
       "      <td>-0.314254</td>\n",
       "      <td>-0.636541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.384228</td>\n",
       "      <td>0.462652</td>\n",
       "      <td>-0.376141</td>\n",
       "      <td>-0.438585</td>\n",
       "      <td>-0.943930</td>\n",
       "      <td>-0.625189</td>\n",
       "      <td>-1.103391</td>\n",
       "      <td>-1.203408</td>\n",
       "      <td>-0.351607</td>\n",
       "      <td>-0.658303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1        f2        f3        f4        f5        f6        f7  \\\n",
       "0 -0.055485 -0.753469 -0.121442 -0.164072 -1.194152 -0.876575 -0.926301   \n",
       "1  1.633965 -1.033798  1.642855  1.728069  0.342875  0.464608  1.263840   \n",
       "2 -0.359963 -0.744974 -0.335050 -0.410421 -1.304365 -0.179940  0.194302   \n",
       "3 -1.068616 -1.484023 -1.045653 -0.944769  0.317555 -0.534964 -0.946579   \n",
       "4 -0.287212  0.282899 -0.335825 -0.349861 -1.664048 -0.929881 -0.961787   \n",
       "\n",
       "         f8        f9       f10    ...          f21       f22       f23  \\\n",
       "0 -0.645289 -0.767734 -1.128128    ...    -0.304937 -0.912142 -0.341934   \n",
       "1  1.301066  0.036827 -0.644680    ...     1.170658 -1.308804  1.193778   \n",
       "2 -0.460613 -1.341897 -0.560035    ...    -0.500265 -0.855047 -0.463588   \n",
       "3 -0.816452  0.003913  0.471973    ...    -0.987617 -1.462060 -0.984688   \n",
       "4 -0.994622 -0.314254 -0.636541    ...    -0.384228  0.462652 -0.376141   \n",
       "\n",
       "        f24       f25       f26       f27       f28       f29       f30  \n",
       "0 -0.370332 -1.325803 -1.016305 -1.176212 -0.618312 -1.296842 -1.145820  \n",
       "1  1.119295  0.219872 -0.373979  0.532401  0.550714 -0.905710 -0.489469  \n",
       "2 -0.527180 -1.514012 -0.207956  0.200199 -0.333986 -1.531864 -0.863074  \n",
       "3 -0.865250  0.078943 -0.622702 -1.056954 -0.839487  0.077266 -0.459635  \n",
       "4 -0.438585 -0.943930 -0.625189 -1.103391 -1.203408 -0.351607 -0.658303  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_normalise_2  = DataFrame(scaler.fit_transform(train_normalise.values), columns = train_normalise.columns, index = train_normalise.index)\n",
    "test_normalise_2  = DataFrame(scaler.fit_transform(test_normalise.values), columns = test_normalise.columns, index = test_normalise.index)\n",
    "\n",
    "train_normalise_2.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Datasets have been normalised:\n",
    "\n",
    "# Now concatenating appending Paient_ID and Diagnosis Comulns to the Normalised Train and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>909410</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8912284</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90317302</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>914102</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID Diagnosis\n",
       "0      909410         B\n",
       "1    84358402         M\n",
       "2     8912284         B\n",
       "3    90317302         B\n",
       "4      914102         B"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['Patient_ID','Diagnosis']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 32), (20, 32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train = pd.concat([train[['Patient_ID','Diagnosis']],train_normalise_2], axis = 1)\n",
    "final_test = pd.concat([test[['Patient_ID','Diagnosis']],test_normalise_2], axis = 1)\n",
    "\n",
    "final_train.shape , final_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Q2: Logistic Regression Model: L1 and L2\n",
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression L1 Model\n",
    "logistic_binary_classifier_L1 = LogisticRegression(penalty = 'l1', C = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partitioning Datasets into: X_train, Y_Train,  X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.drop(['Patient_ID','Diagnosis'], axis = 1)\n",
    "Y_train = train.Diagnosis\n",
    "\n",
    "X_test = test.drop(['Patient_ID','Diagnosis'], axis = 1)\n",
    "Y_test = test.Diagnosis\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "Y_train_le = le.fit_transform(Y_train)\n",
    " \n",
    "Y_test_le = le.fit_transform(Y_test)\n",
    "\n",
    "Y_train_le\n",
    "Y_test_le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 30), (100,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_binary_classifier_L1.fit(X_train, Y_train_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = DataFrame(logistic_binary_classifier_L1.predict(X_test), columns = ['predicted_diagnosis'])\n",
    "logistic_binary_classifier_L1.predict(X_test)\n",
    "\n",
    "predicted_L1 = DataFrame(le.inverse_transform(logistic_binary_classifier_L1.predict(X_test)), columns = ['predicted_diagnosis_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Logistic L1 Classifier Predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>predicted_diagnosis</th>\n",
       "      <th>predicted_diagnosis_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>894047</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892189</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8810528</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>905978</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>871001502</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>87880</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>882488</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>911296202</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>861648</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>895100</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>853612</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8510653</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>88466802</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>911150</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9110944</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9113156</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>859711</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9013579</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>86973701</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>85638502</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Patient_ID Diagnosis  predicted_diagnosis predicted_diagnosis_text\n",
       "0       894047         B                    0                        B\n",
       "1       892189         M                    0                        B\n",
       "2      8810528         B                    0                        B\n",
       "3       905978         B                    0                        B\n",
       "4    871001502         B                    0                        B\n",
       "5        87880         M                    1                        M\n",
       "6       882488         B                    0                        B\n",
       "7    911296202         M                    1                        M\n",
       "8       861648         B                    0                        B\n",
       "9       895100         M                    1                        M\n",
       "10      853612         M                    1                        M\n",
       "11     8510653         B                    0                        B\n",
       "12    88466802         B                    0                        B\n",
       "13      911150         B                    1                        M\n",
       "14     9110944         B                    0                        B\n",
       "15     9113156         B                    0                        B\n",
       "16      859711         B                    0                        B\n",
       "17     9013579         B                    0                        B\n",
       "18    86973701         B                    0                        B\n",
       "19    85638502         M                    1                        M"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at Actual and Predicted Diagnosis together:\n",
    "\n",
    "results_binary_classifier = pd.concat([test[['Patient_ID','Diagnosis']],predicted, predicted_L1], axis =1)\n",
    "\n",
    "print(\"       Logistic L1 Classifier Predictions:\")\n",
    "results_binary_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "# Y_test_le[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic L1 Classifier Evaluation Metrics:\n",
      "\n",
      "Accuracy Score is: 0.9\n",
      "Precision Score is: 0.8333333333333334\n",
      "Recall Score is: 0.8333333333333334\n",
      "F1-Score is: 0.8333333333333334\n",
      "Confusion Matrix is:\n",
      " [[13  1]\n",
      " [ 1  5]]\n"
     ]
    }
   ],
   "source": [
    "# Getting L1 Model Evaluation Metrics:\n",
    "\n",
    "print(\"Logistic L1 Classifier Evaluation Metrics:\\n\")\n",
    "print(\"Accuracy Score is:\",accuracy_score((Y_test_le), Series(logistic_binary_classifier_L1.predict(X_test))))\n",
    "print(\"Precision Score is:\",precision_score((Y_test_le), Series(logistic_binary_classifier_L1.predict(X_test))))\n",
    "print(\"Recall Score is:\",recall_score((Y_test_le), Series(logistic_binary_classifier_L1.predict(X_test))))\n",
    "print(\"F1-Score is:\",f1_score((Y_test_le), logistic_binary_classifier_L1.predict(X_test)))\n",
    "print(\"Confusion Matrix is:\\n\",confusion_matrix((Y_test_le), Series(logistic_binary_classifier_L1.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression L2 Model\n",
    "logistic_binary_classifier_L2 = LogisticRegression(penalty = 'l2', C = 0.1)\n",
    "logistic_binary_classifier_L2.fit(X_train, Y_train_le)\n",
    "\n",
    "predicted_L2 = DataFrame(logistic_binary_classifier_L2.predict(X_test), columns = ['predicted_diagnosis'])\n",
    "predicted_L2_df = DataFrame(le.inverse_transform(logistic_binary_classifier_L2.predict(X_test)), columns = ['predicted_diagnosis_text']) \n",
    "\n",
    "logistic_binary_classifier_L2.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Logistic L2 Classifier Predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>predicted_diagnosis</th>\n",
       "      <th>predicted_diagnosis_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>894047</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892189</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8810528</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>905978</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>871001502</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>87880</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>882488</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>911296202</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>861648</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>895100</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>853612</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8510653</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>88466802</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>911150</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9110944</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9113156</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>859711</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9013579</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>86973701</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>85638502</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Patient_ID Diagnosis  predicted_diagnosis predicted_diagnosis_text\n",
       "0       894047         B                    0                        B\n",
       "1       892189         M                    0                        B\n",
       "2      8810528         B                    0                        B\n",
       "3       905978         B                    0                        B\n",
       "4    871001502         B                    0                        B\n",
       "5        87880         M                    1                        M\n",
       "6       882488         B                    0                        B\n",
       "7    911296202         M                    1                        M\n",
       "8       861648         B                    0                        B\n",
       "9       895100         M                    1                        M\n",
       "10      853612         M                    1                        M\n",
       "11     8510653         B                    0                        B\n",
       "12    88466802         B                    0                        B\n",
       "13      911150         B                    1                        M\n",
       "14     9110944         B                    0                        B\n",
       "15     9113156         B                    0                        B\n",
       "16      859711         B                    0                        B\n",
       "17     9013579         B                    1                        M\n",
       "18    86973701         B                    0                        B\n",
       "19    85638502         M                    1                        M"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at Actual and Predicted Diagnosis together:\n",
    "\n",
    "\n",
    "results_binary_classifier = pd.concat([test[['Patient_ID','Diagnosis']],predicted_L2, predicted_L2_df],axis =1)\n",
    "\n",
    "print(\"       Logistic L2 Classifier Predictions:\")\n",
    "results_binary_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic L2 Classifier Evaluation Metrics:\n",
      "\n",
      "Accuracy Score is: 0.85\n",
      "Precision Score is: 0.7142857142857143\n",
      "Recall Score is: 0.8333333333333334\n",
      "F1-Score is: 0.7692307692307692\n",
      "Confusion Matrix is:\n",
      " [[12  2]\n",
      " [ 1  5]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic L2 Classifier Evaluation Metrics:\\n\")\n",
    "print(\"Accuracy Score is:\",accuracy_score((Y_test_le), Series(logistic_binary_classifier_L2.predict(X_test))))\n",
    "print(\"Precision Score is:\",precision_score((Y_test_le), Series(logistic_binary_classifier_L2.predict(X_test))))\n",
    "print(\"Recall Score is:\",recall_score((Y_test_le), Series(logistic_binary_classifier_L2.predict(X_test))))\n",
    "print(\"F1-Score is:\",f1_score((Y_test_le), logistic_binary_classifier_L2.predict(X_test)))\n",
    "print(\"Confusion Matrix is:\\n\",confusion_matrix((Y_test_le), Series(logistic_binary_classifier_L2.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 1.3 Choosing the best hyper-parameter\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric selected: accuracy\n"
     ]
    }
   ],
   "source": [
    "# My student Id is: \n",
    "\n",
    "student_id = 216337197\n",
    "\n",
    "if (student_id % 3) == 0 : \n",
    "    metric = 'accuracy'\n",
    "elif student_id % 3 == 1: \n",
    "    metric = 'f1_score'\n",
    "elif student_id % 3 == 2: \n",
    "    metric = 'precision'\n",
    "\n",
    "print(\"metric selected:\",metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use: gridsearchCV, K-fold Cross Validation, and pipelining to do task 1.3\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=[FutureWarning])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0   Alpha value: 0.1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "issubclass() arg 2 must be a class or tuple of classes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-9bc3af718ea7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mL1_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'l1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mL1_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_new_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train_new_le\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mL1_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_validate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1278\u001b[0m                              \"positive; got (tol=%r)\" % self.tol)\n\u001b[0;32m   1279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1280\u001b[1;33m         \u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1282\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36m_check_solver\u001b[1;34m(solver, penalty, dual)\u001b[0m\n\u001b[0;32m    431\u001b[0m         warnings.warn(\"Default solver will be changed to 'lbfgs' in 0.22. \"\n\u001b[0;32m    432\u001b[0m                       \u001b[1;34m\"Specify a solver to silence this warning.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                       FutureWarning)\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[0mall_solvers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'liblinear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sag'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'saga'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: issubclass() arg 2 must be a class or tuple of classes"
     ]
    }
   ],
   "source": [
    "# Defining L1 Logistic Model and values for alpha parameter:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "L1_model = LogisticRegression(penalty = 'l1')\n",
    "\n",
    "#alpha_list = {'C':[0.1,1,3,10,33,100,333,1000,3333,10000,33333]}\n",
    "#lambda_list = {'C':[0.001,0.003,0.01,0.03,0.1,0.3,1,3,10,33]}\n",
    "\n",
    "alpha_list  = [0.1,1,3,10,33,100,333,1000,3333,10000,33333]\n",
    "\n",
    "# Performing 10 random splits of the training dataset: \n",
    "\n",
    "# Using a For loop for this:\n",
    "\n",
    "accuracy_matrix  = pd.DataFrame()\n",
    "\n",
    "for p in range(len(alpha_list)):\n",
    "    #len(alpha_list)\n",
    "    \n",
    "    precision_score_list = []\n",
    "    \n",
    "    precision_score_list.append(alpha_list[p])\n",
    "    \n",
    "    print(\"Model:\",p,\"  Alpha value:\",alpha_list[p])\n",
    "    \n",
    "    accuracy_score_model = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        X_train_new_1, X_validate, Y_train_new_1, Y_validate = train_test_split(X_train, Y_train, test_size=0.3, random_state=i)\n",
    "        X_train_new_1.shape, X_validate.shape, Y_train_new_1.shape, Y_validate.shape\n",
    "        #Label Encoder:\n",
    "        Y_train_new_le = le.fit_transform(Y_train_new_1)\n",
    "        Y_validate_le = le.fit_transform(Y_validate)\n",
    "\n",
    "        L1_model = LogisticRegression(penalty = 'l1', C = alpha_list[p])\n",
    "        L1_model.fit(X_train_new_1, Y_train_new_le)\n",
    "        L1_model.predict(X_validate)\n",
    "        \n",
    "        from sklearn.metrics import accuracy_score as acc\n",
    "        from sklearn.metrics import precision_score as pr\n",
    "        from sklearn.metrics import confusion_matrix as cm\n",
    "        \n",
    "        print(\"Accuracy Score is:\",acc((Y_validate_le), Series(L1_model.predict(X_validate))))\n",
    "        \n",
    "        accuracy = acc((Y_validate_le), Series(L1_model.predict(X_validate)))\n",
    "        accuracy_score_model.append(accuracy)\n",
    "        \n",
    "    print(\"Accuracy Scores for Model:\",p, \"\\n\",accuracy_score_model , \"\\n\")\n",
    "    accuracy_matrix = pd.concat([accuracy_matrix, DataFrame(accuracy_score_model, columns = [\"Model%s\" % (p)])],  axis=1)\n",
    "    \n",
    "print((accuracy_matrix),\"\\n\")\n",
    "print(\"Mean Accuracy of Models:\\n\",accuracy_matrix.mean(),\"\\n\")\n",
    "\n",
    "best_alpha_index = int(str(accuracy_matrix.mean().idxmax())[5:])\n",
    "final_alpha = alpha_list[best_alpha_index]\n",
    "\n",
    "print(\"Model with highest accuracy score = \",accuracy_matrix.mean().max(), \" is:\",accuracy_matrix.mean().idxmax(),\n",
    "     \"\\nAnd It has Alpha value =\",alpha_list[best_alpha_index])\n",
    "\n",
    "print(\"final alpha:\",final_alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-training the best L1 model:\n",
    "\n",
    "\n",
    "L1_model = LogisticRegression(penalty = 'l1', C = final_alpha)\n",
    "L1_model.fit(X_train, Y_train_le)\n",
    "L1_model.predict(X_test)\n",
    "\n",
    "print(\"\\n\",L1_model.coef_), print(\"\\n\",L1_model.intercept_,\"\\n\")\n",
    "\n",
    "accuracy = acc((Y_test_le), Series(L1_model.predict(X_test)))\n",
    "precision = pr((Y_test_le), Series(L1_model.predict(X_test)))\n",
    "confusion_m = confusion_matrix((Y_test_le), Series(L1_model.predict(X_test)))\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "model = SelectFromModel(L1_model, prefit=True)\n",
    "model_new = model.transform(X_train)\n",
    "print(model_new.shape, \"\\n\")\n",
    "\n",
    "#model_2_new = SelectKBest(k=5).fit_transform(X_train, Y_train_le)\n",
    "#print(model_2_new.shape), print(model_2_new)\n",
    "\n",
    "print(\"Accuracy = \",accuracy, \"      Precision = \",precision, \"       \\nConfusion Matrix = \\n\",confusion_m)\n",
    "\n",
    "# Top 5 Features in dec order:\n",
    "\n",
    "all_features = DataFrame(L1_model.coef_).max()\n",
    "feature_weights = DataFrame(all_features, columns = ['feature_weights'])\n",
    "feature_weights.sort_values('feature_weights',ascending = False, inplace =True)\n",
    "\n",
    "# Top5 Features and their weights:\n",
    "\n",
    "print(\"\\n Top5 Features and their weights are (index represrnt f1 - f30:\")\n",
    "feature_weights.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0   Lambda value: 0.001\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "issubclass() arg 2 must be a class or tuple of classes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-1010e0769cfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mL1_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'l1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlambda_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mL1_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train_new_le\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mL1_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_validate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1278\u001b[0m                              \"positive; got (tol=%r)\" % self.tol)\n\u001b[0;32m   1279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1280\u001b[1;33m         \u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1282\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36m_check_solver\u001b[1;34m(solver, penalty, dual)\u001b[0m\n\u001b[0;32m    431\u001b[0m         warnings.warn(\"Default solver will be changed to 'lbfgs' in 0.22. \"\n\u001b[0;32m    432\u001b[0m                       \u001b[1;34m\"Specify a solver to silence this warning.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                       FutureWarning)\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[0mall_solvers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'liblinear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sag'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'saga'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: issubclass() arg 2 must be a class or tuple of classes"
     ]
    }
   ],
   "source": [
    "# Defining L2 Logistic Model and values for lambda parameter:\n",
    "\n",
    "L2_model = LogisticRegression(penalty = 'l2')\n",
    "\n",
    "#lambda_list = {'C':[0.001,0.003,0.01,0.03,0.1,0.3,1,3,10,33]}\n",
    "\n",
    "lambda_list  = [0.001,0.003,0.01,0.03,0.1,0.3,1,3,10,33]\n",
    "\n",
    "# Performing 10 random splits of the training dataset: \n",
    "\n",
    "# Using a For loop for this:\n",
    "\n",
    "accuracy_matrix  = pd.DataFrame()\n",
    "\n",
    "for p in range(len(lambda_list)):\n",
    "    #len(lambda_list)\n",
    "    \n",
    "    precision_score_list = []\n",
    "    \n",
    "    precision_score_list.append(lambda_list[p])\n",
    "    \n",
    "    print(\"Model:\",p,\"  Lambda value:\",lambda_list[p])\n",
    "    \n",
    "    accuracy_score_model = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        X_train_new, X_validate, Y_train_new, Y_validate = train_test_split(X_train, Y_train, test_size=0.3, random_state=i)\n",
    "        X_train_new.shape, X_validate.shape, Y_train_new.shape, Y_validate.shape\n",
    "        #Label Encoder:\n",
    "        Y_train_new_le = le.fit_transform(Y_train_new)\n",
    "        Y_validate_le = le.fit_transform(Y_validate)\n",
    "\n",
    "        L1_model = LogisticRegression(penalty = 'l1', C = lambda_list[p])\n",
    "        L1_model.fit(X_train_new, Y_train_new_le)\n",
    "        L1_model.predict(X_validate)\n",
    "        \n",
    "        from sklearn.metrics import accuracy_score as acc\n",
    "        from sklearn.metrics import precision_score as pr\n",
    "        from sklearn.metrics import confusion_matrix as cm\n",
    "        \n",
    "        #print(\"Accuracy Score is:\",acc((Y_validate_le), Series(L1_model.predict(X_validate))))\n",
    "        \n",
    "        accuracy = acc((Y_validate_le), Series(L1_model.predict(X_validate)))\n",
    "        accuracy_score_model.append(accuracy)\n",
    "        \n",
    "    print(\"Accuracy Scores for Model:\",p, \"\\n\",accuracy_score_model , \"\\n\")\n",
    "    accuracy_matrix = pd.concat([accuracy_matrix, DataFrame(accuracy_score_model, columns = [\"Model%s\" % (p)])],  axis=1)\n",
    "    \n",
    "print((accuracy_matrix),\"\\n\")\n",
    "print(\"Mean Accuracy of Models:\\n\",accuracy_matrix.mean(),\"\\n\")\n",
    "\n",
    "best_lambda_index = int(str(accuracy_matrix.mean().idxmax())[5:])\n",
    "final_lambda = lambda_list[best_lambda_index]\n",
    "\n",
    "print(\"Model with highest accuracy score = \",accuracy_matrix.mean().max(), \" is:\",accuracy_matrix.mean().idxmax(),\n",
    "     \"\\nAnd It has Lambda value =\",lambda_list[best_lambda_index])\n",
    "\n",
    "print(\"final lambda:\",final_lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-training the best L2 model:\n",
    "\n",
    "print(\"L2 Model with Final Labmda: \", final_lambda)\n",
    "\n",
    "L2_model = LogisticRegression(penalty = 'l2', C = final_lambda)\n",
    "L2_model.fit(X_train, Y_train_le)\n",
    "L2_model.predict(X_test)\n",
    "\n",
    "print(\"\\n\",L2_model.coef_), print(\"\\n\",L2_model.intercept_,\"\\n\")\n",
    "\n",
    "accuracy = acc((Y_test_le), Series(L2_model.predict(X_test)))\n",
    "precision = pr((Y_test_le), Series(L2_model.predict(X_test)))\n",
    "confusion_m = confusion_matrix((Y_test_le), Series(L2_model.predict(X_test)))\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "model = SelectFromModel(L2_model, prefit=True)\n",
    "model_new = model.transform(X_train)\n",
    "print(model_new.shape, \"\\n\")\n",
    "\n",
    "#model_2_new = SelectKBest(k=5).fit_transform(X_train, Y_train_le)\n",
    "#print(model_2_new.shape), print(model_2_new)\n",
    "\n",
    "print(\"Accuracy = \",accuracy, \"      Precision = \",precision, \"       \\nConfusion Matrix = \\n\",confusion_m)\n",
    "\n",
    "# Top 5 Features in dec order:\n",
    "\n",
    "all_features = DataFrame(L2_model.coef_).max()\n",
    "feature_weights = DataFrame(all_features, columns = ['feature_weights'])\n",
    "feature_weights.sort_values('feature_weights',ascending = False, inplace =True)\n",
    "\n",
    "# Top5 Features and their weights:\n",
    "\n",
    "print(\"\\n Top5 Features and their weights are (index represent f1 - f30:\")\n",
    "feature_weights.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "##Part2: Multi-Class Classification \n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the MSSIT dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      2       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = pd.read_csv(\"reduced_mnist.csv\")\n",
    "\n",
    "mnist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2520, 785)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Data Points =  2520      No of Features =  785\n"
     ]
    }
   ],
   "source": [
    "print(\"No of Data Points = \",mnist.shape[0], \"     No of Features = \", mnist.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([1, 2, 3, 0, 7, 6, 4, 8, 9, 5], dtype='int64')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "1    286\n",
       "2    269\n",
       "3    258\n",
       "0    257\n",
       "7    256\n",
       "6    243\n",
       "4    243\n",
       "8    239\n",
       "9    238\n",
       "5    231"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique Labels in the dataset:\n",
    "print(DataFrame(mnist['label'].value_counts()).index)\n",
    "\n",
    "# Unique Labels and thier counts:\n",
    "DataFrame(mnist['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1764, 784), (1764,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data into train and test:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(mnist.iloc[:,1:], mnist['label'], test_size=0.3, random_state=1)\n",
    "\n",
    "X_train.shape, Y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "issubclass() arg 2 must be a class or tuple of classes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-ef796cf284f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Fitting the One vs Rest Logistic Regression:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mlogistic_one_vs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_vs_rest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mlogistic_one_vs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    213\u001b[0m                 \u001b[1;34m\"not %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                 self.label_binarizer_.classes_[i]])\n\u001b[1;32m--> 215\u001b[1;33m             for i, column in enumerate(columns))\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[1;34m(estimator, X, y, classes)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1278\u001b[0m                              \"positive; got (tol=%r)\" % self.tol)\n\u001b[0;32m   1279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1280\u001b[1;33m         \u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1282\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36m_check_solver\u001b[1;34m(solver, penalty, dual)\u001b[0m\n\u001b[0;32m    431\u001b[0m         warnings.warn(\"Default solver will be changed to 'lbfgs' in 0.22. \"\n\u001b[0;32m    432\u001b[0m                       \u001b[1;34m\"Specify a solver to silence this warning.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                       FutureWarning)\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[0mall_solvers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'liblinear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sag'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'saga'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: issubclass() arg 2 must be a class or tuple of classes"
     ]
    }
   ],
   "source": [
    "# fitting the L1 with alpha = 1 logistic regression one vs rest classifier:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "#Y_train =Y_train.as_matrix().reshape(-1,1)\n",
    "\n",
    "#Y_train_enc = enc.fit(Y_train)\n",
    "\n",
    "#Y_train_enc = enc.fit_transform(Y_train).toarray()\n",
    "\n",
    "l1_mnist = LogisticRegression(penalty = 'l1', C = 1)\n",
    "one_vs_rest = OneVsRestClassifier(l1_mnist)\n",
    "\n",
    "# Fitting the One vs Rest Logistic Regression:\n",
    "\n",
    "logistic_one_vs = one_vs_rest.fit(X_train,Y_train)\n",
    "logistic_one_vs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Model performance on training Data:\n",
    "\n",
    "logistic_one_vs.predict(X_train)\n",
    "accuracy = acc((Y_train), Series(logistic_one_vs.predict(X_train)))\n",
    "accuracy\n",
    "\n",
    "Y_train.head(), Series(logistic_one_vs.predict(X_train)).head()\n",
    "\n",
    "confusion = cm(Series(Y_train), Series(logistic_one_vs.predict(X_train)))\n",
    "\n",
    "print (accuracy)\n",
    "print(confusion)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporting Accuracy, Precision, Recall and Confusion Matrix:\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import precision_score as pr\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.metrics import recall_score as recall\n",
    "\n",
    "accuracy = acc((Y_test), Series(logistic_one_vs.predict(X_test)))\n",
    "#precision = pr((Y_test), Series(logistic_one_vs.predict(X_test)))\n",
    "#recall = recall((Y_test), Series(logistic_one_vs.predict(X_test)))\n",
    "confusion_m = confusion_matrix((Y_test), Series(logistic_one_vs.predict(X_test)))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Accuracy = \",accuracy, \"\\nPrecision = Precision cant be computed for one-vs-rest classification\"  , \n",
    "      \"\\nRecall = Recall cant be computed for one-vs-rest classification\",\"       \\n\\nConfusion Matrix = \\n\",confusion_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2.2 Choosing the best alpha value: will use accuracy as per by student ID caluclation of metric fID = SID %3\n",
    "\n",
    "# Defining L1 Logistic Model and values for alpha parameter:\n",
    "#L1_model = LogisticRegression(penalty = 'l1')\n",
    "\n",
    "alpha_list  = [0.1,1,3,10,33,100,333,1000,3333,10000,33333]\n",
    "\n",
    "# Performing 10 random splits of the training dataset: \n",
    "\n",
    "# Using a For loop for this:\n",
    "\n",
    "validation_accuracy_matrix  = pd.DataFrame()\n",
    "training_accuracy_matrix  = pd.DataFrame()\n",
    "\n",
    "for p in range(len(alpha_list)):\n",
    "    #len(alpha_list)\n",
    "    \n",
    "    precision_score_list = []\n",
    "    \n",
    "    precision_score_list.append(alpha_list[p])\n",
    "    \n",
    "    print(\"Model:\",p,\"  Alpha value:\",alpha_list[p])\n",
    "    \n",
    "    validation_accuracy_score_model = []\n",
    "    training_accuracy_score_model = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        X_train_new, X_validate, Y_train_new, Y_validate = train_test_split(X_train, Y_train, test_size=0.3, random_state=i)\n",
    "        X_train_new.shape, X_validate.shape, Y_train_new.shape, Y_validate.shape\n",
    "        #Label Encoder:\n",
    "        Y_train_new_le = le.fit_transform(Y_train_new)\n",
    "        Y_validate_le = le.fit_transform(Y_validate)\n",
    "        \n",
    "        Lr = LogisticRegression(penalty = 'l1', C = alpha_list[p])\n",
    "\n",
    "        L1_model = OneVsRestClassifier(Lr)\n",
    "        L1_model.fit(X_train_new, Y_train_new_le)\n",
    "        L1_model.predict(X_validate)\n",
    "        \n",
    "        from sklearn.metrics import accuracy_score as acc\n",
    "        from sklearn.metrics import precision_score as pr\n",
    "        from sklearn.metrics import confusion_matrix as cm\n",
    "        \n",
    "        #print(\"Accuracy Score is:\",acc((Y_validate_le), Series(L1_model.predict(X_validate))))\n",
    "        \n",
    "        validation_accuracy = acc((Y_validate_le), Series(L1_model.predict(X_validate)))\n",
    "        validation_accuracy_score_model.append(accuracy)\n",
    "        \n",
    "        training_accuracy = acc((Y_validate_le), Series(L1_model.predict(X_validate)))\n",
    "        training_accuracy_score_model.append(accuracy)\n",
    "        \n",
    "    print(\"Validation Accuracy Scores for Model:\",p, \"\\n\",validation_accuracy_score_model , \"\\n\")\n",
    "    validation_accuracy_matrix = pd.concat([validation_accuracy_matrix, DataFrame(validation_accuracy_score_model, columns = [\"Model%s\" % (p)])],  axis=1)\n",
    "    \n",
    "    print(\"Training Scores for Model:\",p, \"\\n\",training_accuracy_score_model , \"\\n\")\n",
    "    training_accuracy_matrix = pd.concat([training_accuracy_matrix, DataFrame(training_accuracy_score_model, columns = [\"Model%s\" % (p)])],  axis=1)\n",
    "    \n",
    "print((validation_accuracy_matrix),\"\\n\")\n",
    "print(\"Mean Validation Accuracy of Models:\\n\",validation_accuracy_matrix.mean(),\"\\n\")\n",
    "\n",
    "print((training_accuracy_matrix),\"\\n\")\n",
    "print(\"Mean Training Accuracy of Models:\\n\",validation_accuracy_matrix.mean(),\"\\n\")\n",
    "\n",
    "best_alpha_index = int(str(validation_accuracy_matrix.mean().idxmax())[5:])\n",
    "final_alpha = alpha_list[best_alpha_index]\n",
    "\n",
    "print(\"Model with highest Validation accuracy score = \",validation_accuracy_matrix.mean().max(), \" is:\",validation_accuracy_matrix.mean().idxmax(),\n",
    "     \"\\nAnd It has Alpha value =\",alpha_list[best_alpha_index])\n",
    "\n",
    "print(\"final alpha:\",final_alpha)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
