{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Assignment 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Data Munging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the training and testing Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>909410</td>\n",
       "      <td>B</td>\n",
       "      <td>14.02</td>\n",
       "      <td>15.66</td>\n",
       "      <td>89.59</td>\n",
       "      <td>606.5</td>\n",
       "      <td>0.07966</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>0.02087</td>\n",
       "      <td>0.02652</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>19.31</td>\n",
       "      <td>96.53</td>\n",
       "      <td>688.9</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.06260</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.06710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8912284</td>\n",
       "      <td>B</td>\n",
       "      <td>12.89</td>\n",
       "      <td>15.70</td>\n",
       "      <td>84.08</td>\n",
       "      <td>516.6</td>\n",
       "      <td>0.07818</td>\n",
       "      <td>0.09580</td>\n",
       "      <td>0.11150</td>\n",
       "      <td>0.03390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.90</td>\n",
       "      <td>19.69</td>\n",
       "      <td>92.12</td>\n",
       "      <td>595.6</td>\n",
       "      <td>0.09926</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>0.33440</td>\n",
       "      <td>0.10170</td>\n",
       "      <td>0.1999</td>\n",
       "      <td>0.07127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90317302</td>\n",
       "      <td>B</td>\n",
       "      <td>10.26</td>\n",
       "      <td>12.22</td>\n",
       "      <td>65.75</td>\n",
       "      <td>321.6</td>\n",
       "      <td>0.09996</td>\n",
       "      <td>0.07542</td>\n",
       "      <td>0.01923</td>\n",
       "      <td>0.01968</td>\n",
       "      <td>...</td>\n",
       "      <td>11.38</td>\n",
       "      <td>15.65</td>\n",
       "      <td>73.23</td>\n",
       "      <td>394.5</td>\n",
       "      <td>0.13430</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.08615</td>\n",
       "      <td>0.06696</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>0.07722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>914102</td>\n",
       "      <td>B</td>\n",
       "      <td>13.16</td>\n",
       "      <td>20.54</td>\n",
       "      <td>84.06</td>\n",
       "      <td>538.7</td>\n",
       "      <td>0.07335</td>\n",
       "      <td>0.05275</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>0.01256</td>\n",
       "      <td>...</td>\n",
       "      <td>14.50</td>\n",
       "      <td>28.46</td>\n",
       "      <td>95.29</td>\n",
       "      <td>648.3</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.07698</td>\n",
       "      <td>0.04195</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.07429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID Diagnosis     f1     f2      f3      f4       f5       f6  \\\n",
       "0      909410         B  14.02  15.66   89.59   606.5  0.07966  0.05581   \n",
       "1    84358402         M  20.29  14.34  135.10  1297.0  0.10030  0.13280   \n",
       "2     8912284         B  12.89  15.70   84.08   516.6  0.07818  0.09580   \n",
       "3    90317302         B  10.26  12.22   65.75   321.6  0.09996  0.07542   \n",
       "4      914102         B  13.16  20.54   84.06   538.7  0.07335  0.05275   \n",
       "\n",
       "        f7       f8   ...       f21    f22     f23     f24      f25     f26  \\\n",
       "0  0.02087  0.02652   ...     14.91  19.31   96.53   688.9  0.10340  0.1017   \n",
       "1  0.19800  0.10430   ...     22.54  16.67  152.20  1575.0  0.13740  0.2050   \n",
       "2  0.11150  0.03390   ...     13.90  19.69   92.12   595.6  0.09926  0.2317   \n",
       "3  0.01923  0.01968   ...     11.38  15.65   73.23   394.5  0.13430  0.1650   \n",
       "4  0.01800  0.01256   ...     14.50  28.46   95.29   648.3  0.11180  0.1646   \n",
       "\n",
       "       f27      f28     f29      f30  \n",
       "0  0.06260  0.08216  0.2136  0.06710  \n",
       "1  0.40000  0.16250  0.2364  0.07678  \n",
       "2  0.33440  0.10170  0.1999  0.07127  \n",
       "3  0.08615  0.06696  0.2937  0.07722  \n",
       "4  0.07698  0.04195  0.2687  0.07429  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test_wbcd.csv\")\n",
    "train = pd.read_csv(\"train_wbcd.csv\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>894047</td>\n",
       "      <td>B</td>\n",
       "      <td>8.597</td>\n",
       "      <td>18.60</td>\n",
       "      <td>54.09</td>\n",
       "      <td>221.2</td>\n",
       "      <td>0.10740</td>\n",
       "      <td>0.05847</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.952</td>\n",
       "      <td>22.44</td>\n",
       "      <td>56.65</td>\n",
       "      <td>240.1</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.07767</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>0.08116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892189</td>\n",
       "      <td>M</td>\n",
       "      <td>11.760</td>\n",
       "      <td>18.14</td>\n",
       "      <td>75.00</td>\n",
       "      <td>431.1</td>\n",
       "      <td>0.09968</td>\n",
       "      <td>0.05914</td>\n",
       "      <td>0.02685</td>\n",
       "      <td>0.03515</td>\n",
       "      <td>...</td>\n",
       "      <td>13.360</td>\n",
       "      <td>23.39</td>\n",
       "      <td>85.10</td>\n",
       "      <td>553.6</td>\n",
       "      <td>0.1137</td>\n",
       "      <td>0.07974</td>\n",
       "      <td>0.06120</td>\n",
       "      <td>0.07160</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8810528</td>\n",
       "      <td>B</td>\n",
       "      <td>11.840</td>\n",
       "      <td>18.94</td>\n",
       "      <td>75.51</td>\n",
       "      <td>428.0</td>\n",
       "      <td>0.08871</td>\n",
       "      <td>0.06900</td>\n",
       "      <td>0.02669</td>\n",
       "      <td>0.01393</td>\n",
       "      <td>...</td>\n",
       "      <td>13.300</td>\n",
       "      <td>24.99</td>\n",
       "      <td>85.22</td>\n",
       "      <td>546.3</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.18800</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.06913</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>0.07993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>905978</td>\n",
       "      <td>B</td>\n",
       "      <td>9.405</td>\n",
       "      <td>21.70</td>\n",
       "      <td>59.60</td>\n",
       "      <td>271.2</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.06159</td>\n",
       "      <td>0.02047</td>\n",
       "      <td>0.01257</td>\n",
       "      <td>...</td>\n",
       "      <td>10.850</td>\n",
       "      <td>31.24</td>\n",
       "      <td>68.73</td>\n",
       "      <td>359.4</td>\n",
       "      <td>0.1526</td>\n",
       "      <td>0.11930</td>\n",
       "      <td>0.06141</td>\n",
       "      <td>0.03770</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>0.08304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>871001502</td>\n",
       "      <td>B</td>\n",
       "      <td>8.219</td>\n",
       "      <td>20.70</td>\n",
       "      <td>53.27</td>\n",
       "      <td>203.9</td>\n",
       "      <td>0.09405</td>\n",
       "      <td>0.13050</td>\n",
       "      <td>0.13210</td>\n",
       "      <td>0.02168</td>\n",
       "      <td>...</td>\n",
       "      <td>9.092</td>\n",
       "      <td>29.72</td>\n",
       "      <td>58.08</td>\n",
       "      <td>249.8</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>0.53810</td>\n",
       "      <td>0.07879</td>\n",
       "      <td>0.3322</td>\n",
       "      <td>0.14860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID Diagnosis      f1     f2     f3     f4       f5       f6  \\\n",
       "0      894047         B   8.597  18.60  54.09  221.2  0.10740  0.05847   \n",
       "1      892189         M  11.760  18.14  75.00  431.1  0.09968  0.05914   \n",
       "2     8810528         B  11.840  18.94  75.51  428.0  0.08871  0.06900   \n",
       "3      905978         B   9.405  21.70  59.60  271.2  0.10440  0.06159   \n",
       "4   871001502         B   8.219  20.70  53.27  203.9  0.09405  0.13050   \n",
       "\n",
       "        f7       f8   ...        f21    f22    f23    f24     f25      f26  \\\n",
       "0  0.00000  0.00000   ...      8.952  22.44  56.65  240.1  0.1347  0.07767   \n",
       "1  0.02685  0.03515   ...     13.360  23.39  85.10  553.6  0.1137  0.07974   \n",
       "2  0.02669  0.01393   ...     13.300  24.99  85.22  546.3  0.1280  0.18800   \n",
       "3  0.02047  0.01257   ...     10.850  31.24  68.73  359.4  0.1526  0.11930   \n",
       "4  0.13210  0.02168   ...      9.092  29.72  58.08  249.8  0.1630  0.43100   \n",
       "\n",
       "       f27      f28     f29      f30  \n",
       "0  0.00000  0.00000  0.3142  0.08116  \n",
       "1  0.06120  0.07160  0.1978  0.06915  \n",
       "2  0.14710  0.06913  0.2535  0.07993  \n",
       "3  0.06141  0.03770  0.2872  0.08304  \n",
       "4  0.53810  0.07879  0.3322  0.14860  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbcd = [train,test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 32), (20, 32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns\n",
    "# No of Features/Columns in DataSet: = 32\n",
    "len(train.columns), len(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Features in test: \n",
      " {'B': 14, 'M': 6}\n",
      "\n",
      "\n",
      "No of Features in train: \n",
      " {'B': 58, 'M': 42}\n"
     ]
    }
   ],
   "source": [
    "# No of Features Values for B and M in Test Dataset\n",
    "\n",
    "print(\"No of Features in test:\", \"\\n\",test['Diagnosis'].value_counts().to_dict())\n",
    "print(\"\\n\")\n",
    "print(\"No of Features in train:\", \"\\n\",train['Diagnosis'].value_counts().to_dict())\n",
    "\n",
    "# Expressing as % of Total:\n",
    "\n",
    "\n",
    "#print(\"No of Features in test:\", \"\\n\",test['Diagnosis'].value_counts() / test['Diagnosis'].count .to_dict())\n",
    "#print(\"\\n\")\n",
    "#print(\"No of Features in train:\", \"\\n\",train['Diagnosis'].value_counts().to_dict())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Patient_ID    0\n",
       " Diagnosis     0\n",
       " f1            0\n",
       " f2            0\n",
       " f3            0\n",
       " f4            0\n",
       " f5            0\n",
       " f6            0\n",
       " f7            0\n",
       " f8            0\n",
       " f9            0\n",
       " f10           0\n",
       " f11           0\n",
       " f12           0\n",
       " f13           0\n",
       " f14           0\n",
       " f15           0\n",
       " f16           0\n",
       " f17           0\n",
       " f18           0\n",
       " f19           0\n",
       " f20           0\n",
       " f21           2\n",
       " f22           0\n",
       " f23           0\n",
       " f24           0\n",
       " f25           0\n",
       " f26           0\n",
       " f27           0\n",
       " f28           0\n",
       " f29           0\n",
       " f30           0\n",
       " dtype: int64, Patient_ID    0\n",
       " Diagnosis     0\n",
       " f1            0\n",
       " f2            0\n",
       " f3            0\n",
       " f4            0\n",
       " f5            0\n",
       " f6            0\n",
       " f7            0\n",
       " f8            0\n",
       " f9            0\n",
       " f10           0\n",
       " f11           0\n",
       " f12           0\n",
       " f13           0\n",
       " f14           0\n",
       " f15           0\n",
       " f16           0\n",
       " f17           0\n",
       " f18           0\n",
       " f19           0\n",
       " f20           0\n",
       " f21           1\n",
       " f22           0\n",
       " f23           0\n",
       " f24           0\n",
       " f25           0\n",
       " f26           0\n",
       " f27           0\n",
       " f28           0\n",
       " f29           0\n",
       " f30           0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHecking for Null values in each column in test dataset:\n",
    "train.isna().sum(), test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No missing Values in testing Dataset. \n",
    "# Checking for Zero Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Patient_ID    0\n",
       " Diagnosis     0\n",
       " f1            0\n",
       " f2            0\n",
       " f3            0\n",
       " f4            0\n",
       " f5            0\n",
       " f6            0\n",
       " f7            6\n",
       " f8            6\n",
       " f9            0\n",
       " f10           0\n",
       " f11           0\n",
       " f12           0\n",
       " f13           0\n",
       " f14           0\n",
       " f15           0\n",
       " f16           0\n",
       " f17           6\n",
       " f18           6\n",
       " f19           0\n",
       " f20           0\n",
       " f21           0\n",
       " f22           0\n",
       " f23           0\n",
       " f24           0\n",
       " f25           0\n",
       " f26           0\n",
       " f27           6\n",
       " f28           6\n",
       " f29           0\n",
       " f30           0\n",
       " dtype: int64, Patient_ID    0\n",
       " Diagnosis     0\n",
       " f1            0\n",
       " f2            0\n",
       " f3            0\n",
       " f4            0\n",
       " f5            0\n",
       " f6            0\n",
       " f7            1\n",
       " f8            1\n",
       " f9            0\n",
       " f10           0\n",
       " f11           0\n",
       " f12           0\n",
       " f13           0\n",
       " f14           0\n",
       " f15           0\n",
       " f16           0\n",
       " f17           1\n",
       " f18           1\n",
       " f19           0\n",
       " f20           0\n",
       " f21           0\n",
       " f22           0\n",
       " f23           0\n",
       " f24           0\n",
       " f25           0\n",
       " f26           0\n",
       " f27           1\n",
       " f28           1\n",
       " f29           0\n",
       " f30           0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.eq(0).sum(), test.eq(0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above output we can see that: \n",
    "#feature f7, f8, f17, f18, f27 and f28 each have 6 zero value each - Train Dataset\n",
    "#feature f7, f8, f17, f18, f27 and f28 each have 1 zero value each - Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.160791e+07</td>\n",
       "      <td>14.225920</td>\n",
       "      <td>19.207900</td>\n",
       "      <td>92.722600</td>\n",
       "      <td>666.375000</td>\n",
       "      <td>0.095696</td>\n",
       "      <td>0.106129</td>\n",
       "      <td>0.090364</td>\n",
       "      <td>0.049346</td>\n",
       "      <td>0.179893</td>\n",
       "      <td>...</td>\n",
       "      <td>16.486765</td>\n",
       "      <td>25.380800</td>\n",
       "      <td>108.925200</td>\n",
       "      <td>909.191000</td>\n",
       "      <td>0.132563</td>\n",
       "      <td>0.265144</td>\n",
       "      <td>0.278176</td>\n",
       "      <td>0.117597</td>\n",
       "      <td>0.289196</td>\n",
       "      <td>0.083999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.737600e+07</td>\n",
       "      <td>3.729963</td>\n",
       "      <td>4.732476</td>\n",
       "      <td>25.924925</td>\n",
       "      <td>366.768846</td>\n",
       "      <td>0.013496</td>\n",
       "      <td>0.057694</td>\n",
       "      <td>0.084449</td>\n",
       "      <td>0.042066</td>\n",
       "      <td>0.027482</td>\n",
       "      <td>...</td>\n",
       "      <td>5.250147</td>\n",
       "      <td>6.689072</td>\n",
       "      <td>36.432902</td>\n",
       "      <td>597.843396</td>\n",
       "      <td>0.022108</td>\n",
       "      <td>0.161632</td>\n",
       "      <td>0.210617</td>\n",
       "      <td>0.075227</td>\n",
       "      <td>0.058586</td>\n",
       "      <td>0.014823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>7.729000</td>\n",
       "      <td>10.820000</td>\n",
       "      <td>47.980000</td>\n",
       "      <td>178.800000</td>\n",
       "      <td>0.068830</td>\n",
       "      <td>0.023440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.077000</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>57.170000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156600</td>\n",
       "      <td>0.059050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.650350e+05</td>\n",
       "      <td>11.880000</td>\n",
       "      <td>15.607500</td>\n",
       "      <td>75.667500</td>\n",
       "      <td>430.825000</td>\n",
       "      <td>0.084645</td>\n",
       "      <td>0.062065</td>\n",
       "      <td>0.025070</td>\n",
       "      <td>0.019017</td>\n",
       "      <td>0.161700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.052500</td>\n",
       "      <td>19.510000</td>\n",
       "      <td>84.055000</td>\n",
       "      <td>514.925000</td>\n",
       "      <td>0.119275</td>\n",
       "      <td>0.156575</td>\n",
       "      <td>0.093762</td>\n",
       "      <td>0.060362</td>\n",
       "      <td>0.246875</td>\n",
       "      <td>0.073960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.013015e+05</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>18.805000</td>\n",
       "      <td>87.355000</td>\n",
       "      <td>572.050000</td>\n",
       "      <td>0.094985</td>\n",
       "      <td>0.096485</td>\n",
       "      <td>0.066145</td>\n",
       "      <td>0.032565</td>\n",
       "      <td>0.179700</td>\n",
       "      <td>...</td>\n",
       "      <td>15.315000</td>\n",
       "      <td>25.670000</td>\n",
       "      <td>98.245000</td>\n",
       "      <td>727.100000</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.237700</td>\n",
       "      <td>0.256650</td>\n",
       "      <td>0.104250</td>\n",
       "      <td>0.279600</td>\n",
       "      <td>0.081660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.821689e+06</td>\n",
       "      <td>15.707500</td>\n",
       "      <td>21.917500</td>\n",
       "      <td>103.650000</td>\n",
       "      <td>768.325000</td>\n",
       "      <td>0.103825</td>\n",
       "      <td>0.130025</td>\n",
       "      <td>0.135875</td>\n",
       "      <td>0.076825</td>\n",
       "      <td>0.193400</td>\n",
       "      <td>...</td>\n",
       "      <td>19.147500</td>\n",
       "      <td>30.870000</td>\n",
       "      <td>125.450000</td>\n",
       "      <td>1110.250000</td>\n",
       "      <td>0.147875</td>\n",
       "      <td>0.357050</td>\n",
       "      <td>0.400900</td>\n",
       "      <td>0.173950</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>0.093808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.197970e+07</td>\n",
       "      <td>25.220000</td>\n",
       "      <td>32.470000</td>\n",
       "      <td>171.500000</td>\n",
       "      <td>1878.000000</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.311400</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.184500</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>...</td>\n",
       "      <td>31.010000</td>\n",
       "      <td>45.410000</td>\n",
       "      <td>211.700000</td>\n",
       "      <td>2944.000000</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.758400</td>\n",
       "      <td>0.960800</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.475300</td>\n",
       "      <td>0.128400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Patient_ID          f1          f2          f3           f4  \\\n",
       "count  1.000000e+02  100.000000  100.000000  100.000000   100.000000   \n",
       "mean   1.160791e+07   14.225920   19.207900   92.722600   666.375000   \n",
       "std    2.737600e+07    3.729963    4.732476   25.924925   366.768846   \n",
       "min    8.670000e+03    7.729000   10.820000   47.980000   178.800000   \n",
       "25%    8.650350e+05   11.880000   15.607500   75.667500   430.825000   \n",
       "50%    9.013015e+05   13.600000   18.805000   87.355000   572.050000   \n",
       "75%    2.821689e+06   15.707500   21.917500  103.650000   768.325000   \n",
       "max    9.197970e+07   25.220000   32.470000  171.500000  1878.000000   \n",
       "\n",
       "               f5          f6          f7          f8          f9     ...      \\\n",
       "count  100.000000  100.000000  100.000000  100.000000  100.000000     ...       \n",
       "mean     0.095696    0.106129    0.090364    0.049346    0.179893     ...       \n",
       "std      0.013496    0.057694    0.084449    0.042066    0.027482     ...       \n",
       "min      0.068830    0.023440    0.000000    0.000000    0.106000     ...       \n",
       "25%      0.084645    0.062065    0.025070    0.019017    0.161700     ...       \n",
       "50%      0.094985    0.096485    0.066145    0.032565    0.179700     ...       \n",
       "75%      0.103825    0.130025    0.135875    0.076825    0.193400     ...       \n",
       "max      0.132600    0.311400    0.426400    0.184500    0.255600     ...       \n",
       "\n",
       "             f21         f22         f23          f24         f25         f26  \\\n",
       "count  98.000000  100.000000  100.000000   100.000000  100.000000  100.000000   \n",
       "mean   16.486765   25.380800  108.925200   909.191000    0.132563    0.265144   \n",
       "std     5.250147    6.689072   36.432902   597.843396    0.022108    0.161632   \n",
       "min     9.077000   14.100000   57.170000   248.000000    0.071170    0.027290   \n",
       "25%    13.052500   19.510000   84.055000   514.925000    0.119275    0.156575   \n",
       "50%    15.315000   25.670000   98.245000   727.100000    0.134300    0.237700   \n",
       "75%    19.147500   30.870000  125.450000  1110.250000    0.147875    0.357050   \n",
       "max    31.010000   45.410000  211.700000  2944.000000    0.187800    0.758400   \n",
       "\n",
       "              f27         f28         f29         f30  \n",
       "count  100.000000  100.000000  100.000000  100.000000  \n",
       "mean     0.278176    0.117597    0.289196    0.083999  \n",
       "std      0.210617    0.075227    0.058586    0.014823  \n",
       "min      0.000000    0.000000    0.156600    0.059050  \n",
       "25%      0.093762    0.060362    0.246875    0.073960  \n",
       "50%      0.256650    0.104250    0.279600    0.081660  \n",
       "75%      0.400900    0.173950    0.320600    0.093808  \n",
       "max      0.960800    0.291000    0.475300    0.128400  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doing some EDA on all the features:\n",
    "\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Patient_ID': 104798968.6,\n",
       " 'f1': 13.267300000000002,\n",
       " 'f2': 20.8295,\n",
       " 'f3': 86.425,\n",
       " 'f4': 608.79,\n",
       " 'f5': 0.09692150000000001,\n",
       " 'f6': 0.10302800000000001,\n",
       " 'f7': 0.08280999999999998,\n",
       " 'f8': 0.041847499999999996,\n",
       " 'f9': 0.18865,\n",
       " 'f10': 0.06598250000000001,\n",
       " 'f11': 0.45153499999999996,\n",
       " 'f12': 1.3734399999999998,\n",
       " 'f13': 3.1300999999999997,\n",
       " 'f14': 52.98449999999999,\n",
       " 'f15': 0.007996399999999999,\n",
       " 'f16': 0.026536499999999998,\n",
       " 'f17': 0.028184899999999995,\n",
       " 'f18': 0.010051099999999999,\n",
       " 'f19': 0.022621999999999996,\n",
       " 'f20': 0.004965750000000001,\n",
       " 'f21': 15.574578947368423,\n",
       " 'f22': 27.935000000000002,\n",
       " 'f23': 102.66799999999998,\n",
       " 'f24': 865.9350000000002,\n",
       " 'f25': 0.13654499999999997,\n",
       " 'f26': 0.259443,\n",
       " 'f27': 0.2613675,\n",
       " 'f28': 0.100253,\n",
       " 'f29': 0.31510999999999995,\n",
       " 'f30': 0.08921899999999999}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from the above output we can see that the mean and median, and they look quite close\n",
    "# Using the Mean to fill out the zero values:\n",
    "\n",
    "# Calculating the mean first\n",
    "\n",
    "mean_values_train = train.mean().to_dict()\n",
    "mean_values_train\n",
    "\n",
    "mean_values_test = test.mean().to_dict()\n",
    "mean_values_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Patient_ID    0\n",
       "Diagnosis     0\n",
       "f1            0\n",
       "f2            0\n",
       "f3            0\n",
       "f4            0\n",
       "f5            0\n",
       "f6            0\n",
       "f7            6\n",
       "f8            6\n",
       "f9            0\n",
       "f10           0\n",
       "f11           0\n",
       "f12           0\n",
       "f13           0\n",
       "f14           0\n",
       "f15           0\n",
       "f16           0\n",
       "f17           6\n",
       "f18           6\n",
       "f19           0\n",
       "f20           0\n",
       "f21           2\n",
       "f22           0\n",
       "f23           0\n",
       "f24           0\n",
       "f25           0\n",
       "f26           0\n",
       "f27           6\n",
       "f28           6\n",
       "f29           0\n",
       "f30           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filling the mean in lieu of the zero value:\n",
    "    # Here we will use the fillna method for convenince, so first will replace all zeros with nan (nulls) and then use fillna()\n",
    "\n",
    "train[train == 0] = np.nan    \n",
    "test[test == 0] = np.nan\n",
    "\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Null values using the fillna method:\n",
    "train = train.fillna(value = mean_values_train)\n",
    "test = test.fillna(value = mean_values_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Patient_ID    0\n",
       "Diagnosis     0\n",
       "f1            0\n",
       "f2            0\n",
       "f3            0\n",
       "f4            0\n",
       "f5            0\n",
       "f6            0\n",
       "f7            0\n",
       "f8            0\n",
       "f9            0\n",
       "f10           0\n",
       "f11           0\n",
       "f12           0\n",
       "f13           0\n",
       "f14           0\n",
       "f15           0\n",
       "f16           0\n",
       "f17           0\n",
       "f18           0\n",
       "f19           0\n",
       "f20           0\n",
       "f21           0\n",
       "f22           0\n",
       "f23           0\n",
       "f24           0\n",
       "f25           0\n",
       "f26           0\n",
       "f27           0\n",
       "f28           0\n",
       "f29           0\n",
       "f30           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Again if there are any Null values:\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the testing and training datasets: Using Standardised Z Scores:\n",
    "#Normalising only the columns f1 - f30 since other 2 are not numeric columns\n",
    "\n",
    "train_normalise = train.drop(['Patient_ID','Diagnosis'], axis = 1)\n",
    "\n",
    "test_normalise = test.drop(['Patient_ID','Diagnosis'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.02</td>\n",
       "      <td>15.66</td>\n",
       "      <td>89.59</td>\n",
       "      <td>606.5</td>\n",
       "      <td>0.07966</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>0.02087</td>\n",
       "      <td>0.02652</td>\n",
       "      <td>0.1589</td>\n",
       "      <td>0.05586</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>19.31</td>\n",
       "      <td>96.53</td>\n",
       "      <td>688.9</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.06260</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.06710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.89</td>\n",
       "      <td>15.70</td>\n",
       "      <td>84.08</td>\n",
       "      <td>516.6</td>\n",
       "      <td>0.07818</td>\n",
       "      <td>0.09580</td>\n",
       "      <td>0.11150</td>\n",
       "      <td>0.03390</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.05935</td>\n",
       "      <td>...</td>\n",
       "      <td>13.90</td>\n",
       "      <td>19.69</td>\n",
       "      <td>92.12</td>\n",
       "      <td>595.6</td>\n",
       "      <td>0.09926</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>0.33440</td>\n",
       "      <td>0.10170</td>\n",
       "      <td>0.1999</td>\n",
       "      <td>0.07127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.26</td>\n",
       "      <td>12.22</td>\n",
       "      <td>65.75</td>\n",
       "      <td>321.6</td>\n",
       "      <td>0.09996</td>\n",
       "      <td>0.07542</td>\n",
       "      <td>0.01923</td>\n",
       "      <td>0.01968</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.06569</td>\n",
       "      <td>...</td>\n",
       "      <td>11.38</td>\n",
       "      <td>15.65</td>\n",
       "      <td>73.23</td>\n",
       "      <td>394.5</td>\n",
       "      <td>0.13430</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.08615</td>\n",
       "      <td>0.06696</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>0.07722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.16</td>\n",
       "      <td>20.54</td>\n",
       "      <td>84.06</td>\n",
       "      <td>538.7</td>\n",
       "      <td>0.07335</td>\n",
       "      <td>0.05275</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>0.01256</td>\n",
       "      <td>0.1713</td>\n",
       "      <td>0.05888</td>\n",
       "      <td>...</td>\n",
       "      <td>14.50</td>\n",
       "      <td>28.46</td>\n",
       "      <td>95.29</td>\n",
       "      <td>648.3</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.07698</td>\n",
       "      <td>0.04195</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.07429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      f1     f2      f3      f4       f5       f6       f7       f8      f9  \\\n",
       "0  14.02  15.66   89.59   606.5  0.07966  0.05581  0.02087  0.02652  0.1589   \n",
       "1  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
       "2  12.89  15.70   84.08   516.6  0.07818  0.09580  0.11150  0.03390  0.1432   \n",
       "3  10.26  12.22   65.75   321.6  0.09996  0.07542  0.01923  0.01968  0.1800   \n",
       "4  13.16  20.54   84.06   538.7  0.07335  0.05275  0.01800  0.01256  0.1713   \n",
       "\n",
       "       f10   ...       f21    f22     f23     f24      f25     f26      f27  \\\n",
       "0  0.05586   ...     14.91  19.31   96.53   688.9  0.10340  0.1017  0.06260   \n",
       "1  0.05883   ...     22.54  16.67  152.20  1575.0  0.13740  0.2050  0.40000   \n",
       "2  0.05935   ...     13.90  19.69   92.12   595.6  0.09926  0.2317  0.33440   \n",
       "3  0.06569   ...     11.38  15.65   73.23   394.5  0.13430  0.1650  0.08615   \n",
       "4  0.05888   ...     14.50  28.46   95.29   648.3  0.11180  0.1646  0.07698   \n",
       "\n",
       "       f28     f29      f30  \n",
       "0  0.08216  0.2136  0.06710  \n",
       "1  0.16250  0.2364  0.07678  \n",
       "2  0.10170  0.1999  0.07127  \n",
       "3  0.06696  0.2937  0.07722  \n",
       "4  0.04195  0.2687  0.07429  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_normalise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.055485</td>\n",
       "      <td>-0.753469</td>\n",
       "      <td>-0.121442</td>\n",
       "      <td>-0.164072</td>\n",
       "      <td>-1.194152</td>\n",
       "      <td>-0.876575</td>\n",
       "      <td>-0.926301</td>\n",
       "      <td>-0.645289</td>\n",
       "      <td>-0.767734</td>\n",
       "      <td>-1.128128</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.304937</td>\n",
       "      <td>-0.912142</td>\n",
       "      <td>-0.341934</td>\n",
       "      <td>-0.370332</td>\n",
       "      <td>-1.325803</td>\n",
       "      <td>-1.016305</td>\n",
       "      <td>-1.176212</td>\n",
       "      <td>-0.618312</td>\n",
       "      <td>-1.296842</td>\n",
       "      <td>-1.145820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.633965</td>\n",
       "      <td>-1.033798</td>\n",
       "      <td>1.642855</td>\n",
       "      <td>1.728069</td>\n",
       "      <td>0.342875</td>\n",
       "      <td>0.464608</td>\n",
       "      <td>1.263840</td>\n",
       "      <td>1.301066</td>\n",
       "      <td>0.036827</td>\n",
       "      <td>-0.644680</td>\n",
       "      <td>...</td>\n",
       "      <td>1.170658</td>\n",
       "      <td>-1.308804</td>\n",
       "      <td>1.193778</td>\n",
       "      <td>1.119295</td>\n",
       "      <td>0.219872</td>\n",
       "      <td>-0.373979</td>\n",
       "      <td>0.532401</td>\n",
       "      <td>0.550714</td>\n",
       "      <td>-0.905710</td>\n",
       "      <td>-0.489469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.359963</td>\n",
       "      <td>-0.744974</td>\n",
       "      <td>-0.335050</td>\n",
       "      <td>-0.410421</td>\n",
       "      <td>-1.304365</td>\n",
       "      <td>-0.179940</td>\n",
       "      <td>0.194302</td>\n",
       "      <td>-0.460613</td>\n",
       "      <td>-1.341897</td>\n",
       "      <td>-0.560035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.500265</td>\n",
       "      <td>-0.855047</td>\n",
       "      <td>-0.463588</td>\n",
       "      <td>-0.527180</td>\n",
       "      <td>-1.514012</td>\n",
       "      <td>-0.207956</td>\n",
       "      <td>0.200199</td>\n",
       "      <td>-0.333986</td>\n",
       "      <td>-1.531864</td>\n",
       "      <td>-0.863074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.068616</td>\n",
       "      <td>-1.484023</td>\n",
       "      <td>-1.045653</td>\n",
       "      <td>-0.944769</td>\n",
       "      <td>0.317555</td>\n",
       "      <td>-0.534964</td>\n",
       "      <td>-0.946579</td>\n",
       "      <td>-0.816452</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>0.471973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987617</td>\n",
       "      <td>-1.462060</td>\n",
       "      <td>-0.984688</td>\n",
       "      <td>-0.865250</td>\n",
       "      <td>0.078943</td>\n",
       "      <td>-0.622702</td>\n",
       "      <td>-1.056954</td>\n",
       "      <td>-0.839487</td>\n",
       "      <td>0.077266</td>\n",
       "      <td>-0.459635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.287212</td>\n",
       "      <td>0.282899</td>\n",
       "      <td>-0.335825</td>\n",
       "      <td>-0.349861</td>\n",
       "      <td>-1.664048</td>\n",
       "      <td>-0.929881</td>\n",
       "      <td>-0.961787</td>\n",
       "      <td>-0.994622</td>\n",
       "      <td>-0.314254</td>\n",
       "      <td>-0.636541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.384228</td>\n",
       "      <td>0.462652</td>\n",
       "      <td>-0.376141</td>\n",
       "      <td>-0.438585</td>\n",
       "      <td>-0.943930</td>\n",
       "      <td>-0.625189</td>\n",
       "      <td>-1.103391</td>\n",
       "      <td>-1.203408</td>\n",
       "      <td>-0.351607</td>\n",
       "      <td>-0.658303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1        f2        f3        f4        f5        f6        f7  \\\n",
       "0 -0.055485 -0.753469 -0.121442 -0.164072 -1.194152 -0.876575 -0.926301   \n",
       "1  1.633965 -1.033798  1.642855  1.728069  0.342875  0.464608  1.263840   \n",
       "2 -0.359963 -0.744974 -0.335050 -0.410421 -1.304365 -0.179940  0.194302   \n",
       "3 -1.068616 -1.484023 -1.045653 -0.944769  0.317555 -0.534964 -0.946579   \n",
       "4 -0.287212  0.282899 -0.335825 -0.349861 -1.664048 -0.929881 -0.961787   \n",
       "\n",
       "         f8        f9       f10    ...          f21       f22       f23  \\\n",
       "0 -0.645289 -0.767734 -1.128128    ...    -0.304937 -0.912142 -0.341934   \n",
       "1  1.301066  0.036827 -0.644680    ...     1.170658 -1.308804  1.193778   \n",
       "2 -0.460613 -1.341897 -0.560035    ...    -0.500265 -0.855047 -0.463588   \n",
       "3 -0.816452  0.003913  0.471973    ...    -0.987617 -1.462060 -0.984688   \n",
       "4 -0.994622 -0.314254 -0.636541    ...    -0.384228  0.462652 -0.376141   \n",
       "\n",
       "        f24       f25       f26       f27       f28       f29       f30  \n",
       "0 -0.370332 -1.325803 -1.016305 -1.176212 -0.618312 -1.296842 -1.145820  \n",
       "1  1.119295  0.219872 -0.373979  0.532401  0.550714 -0.905710 -0.489469  \n",
       "2 -0.527180 -1.514012 -0.207956  0.200199 -0.333986 -1.531864 -0.863074  \n",
       "3 -0.865250  0.078943 -0.622702 -1.056954 -0.839487  0.077266 -0.459635  \n",
       "4 -0.438585 -0.943930 -0.625189 -1.103391 -1.203408 -0.351607 -0.658303  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_normalise_2  = DataFrame(scaler.fit_transform(train_normalise.values), columns = train_normalise.columns, index = train_normalise.index)\n",
    "test_normalise_2  = DataFrame(scaler.fit_transform(test_normalise.values), columns = test_normalise.columns, index = test_normalise.index)\n",
    "\n",
    "train_normalise_2.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Datasets have been normalised:\n",
    "\n",
    "# Now concatenating appending Paient_ID and Diagnosis Comulns to the Normalised Train and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>909410</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8912284</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90317302</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>914102</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID Diagnosis\n",
       "0      909410         B\n",
       "1    84358402         M\n",
       "2     8912284         B\n",
       "3    90317302         B\n",
       "4      914102         B"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['Patient_ID','Diagnosis']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 32), (20, 32))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train = pd.concat([train[['Patient_ID','Diagnosis']],train_normalise_2], axis = 1)\n",
    "final_test = pd.concat([test[['Patient_ID','Diagnosis']],test_normalise_2], axis = 1)\n",
    "\n",
    "final_train.shape , final_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Q2: Logistic Regression Model: L1 and L2\n",
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression L1 Model\n",
    "logistic_binary_classifier_L1 = LogisticRegression(penalty = 'l1', C = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partitioning Datasets into: X_train, Y_Train,  X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.drop(['Patient_ID','Diagnosis'], axis = 1)\n",
    "Y_train = train.Diagnosis\n",
    "\n",
    "X_test = test.drop(['Patient_ID','Diagnosis'], axis = 1)\n",
    "Y_test = test.Diagnosis\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "Y_train_le = le.fit_transform(Y_train)\n",
    " \n",
    "Y_test_le = le.fit_transform(Y_test)\n",
    "\n",
    "Y_train_le\n",
    "Y_test_le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 30), (100,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_binary_classifier_L1.fit(X_train, Y_train_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = DataFrame(logistic_binary_classifier_L1.predict(X_test), columns = ['predicted_diagnosis'])\n",
    "logistic_binary_classifier_L1.predict(X_test)\n",
    "\n",
    "predicted_L1 = DataFrame(le.inverse_transform(logistic_binary_classifier_L1.predict(X_test)), columns = ['predicted_diagnosis_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Logistic L1 Classifier Predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>predicted_diagnosis</th>\n",
       "      <th>predicted_diagnosis_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>894047</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892189</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8810528</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>905978</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>871001502</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>87880</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>882488</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>911296202</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>861648</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>895100</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>853612</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8510653</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>88466802</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>911150</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9110944</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9113156</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>859711</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9013579</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>86973701</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>85638502</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Patient_ID Diagnosis  predicted_diagnosis predicted_diagnosis_text\n",
       "0       894047         B                    0                        B\n",
       "1       892189         M                    0                        B\n",
       "2      8810528         B                    0                        B\n",
       "3       905978         B                    0                        B\n",
       "4    871001502         B                    0                        B\n",
       "5        87880         M                    1                        M\n",
       "6       882488         B                    0                        B\n",
       "7    911296202         M                    1                        M\n",
       "8       861648         B                    0                        B\n",
       "9       895100         M                    1                        M\n",
       "10      853612         M                    1                        M\n",
       "11     8510653         B                    0                        B\n",
       "12    88466802         B                    0                        B\n",
       "13      911150         B                    1                        M\n",
       "14     9110944         B                    0                        B\n",
       "15     9113156         B                    0                        B\n",
       "16      859711         B                    0                        B\n",
       "17     9013579         B                    0                        B\n",
       "18    86973701         B                    0                        B\n",
       "19    85638502         M                    1                        M"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at Actual and Predicted Diagnosis together:\n",
    "\n",
    "results_binary_classifier = pd.concat([test[['Patient_ID','Diagnosis']],predicted, predicted_L1], axis =1)\n",
    "\n",
    "print(\"       Logistic L1 Classifier Predictions:\")\n",
    "results_binary_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "# Y_test_le[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic L1 Classifier Evaluation Metrics:\n",
      "\n",
      "Accuracy Score is: 0.9\n",
      "Precision Score is: 0.8333333333333334\n",
      "Recall Score is: 0.8333333333333334\n",
      "F1-Score is: 0.8333333333333334\n",
      "Confusion Matrix is:\n",
      " [[13  1]\n",
      " [ 1  5]]\n"
     ]
    }
   ],
   "source": [
    "# Getting L1 Model Evaluation Metrics:\n",
    "\n",
    "print(\"Logistic L1 Classifier Evaluation Metrics:\\n\")\n",
    "print(\"Accuracy Score is:\",accuracy_score((Y_test_le), Series(logistic_binary_classifier_L1.predict(X_test))))\n",
    "print(\"Precision Score is:\",precision_score((Y_test_le), Series(logistic_binary_classifier_L1.predict(X_test))))\n",
    "print(\"Recall Score is:\",recall_score((Y_test_le), Series(logistic_binary_classifier_L1.predict(X_test))))\n",
    "print(\"F1-Score is:\",f1_score((Y_test_le), logistic_binary_classifier_L1.predict(X_test)))\n",
    "print(\"Confusion Matrix is:\\n\",confusion_matrix((Y_test_le), Series(logistic_binary_classifier_L1.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression L2 Model\n",
    "logistic_binary_classifier_L2 = LogisticRegression(penalty = 'l2', C = 0.1)\n",
    "logistic_binary_classifier_L2.fit(X_train, Y_train_le)\n",
    "\n",
    "predicted_L2 = DataFrame(logistic_binary_classifier_L2.predict(X_test), columns = ['predicted_diagnosis'])\n",
    "predicted_L2_df = DataFrame(le.inverse_transform(logistic_binary_classifier_L2.predict(X_test)), columns = ['predicted_diagnosis_text']) \n",
    "\n",
    "logistic_binary_classifier_L2.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Logistic L2 Classifier Predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>predicted_diagnosis</th>\n",
       "      <th>predicted_diagnosis_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>894047</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892189</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8810528</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>905978</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>871001502</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>87880</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>882488</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>911296202</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>861648</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>895100</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>853612</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8510653</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>88466802</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>911150</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9110944</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9113156</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>859711</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9013579</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>86973701</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>85638502</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Patient_ID Diagnosis  predicted_diagnosis predicted_diagnosis_text\n",
       "0       894047         B                    0                        B\n",
       "1       892189         M                    0                        B\n",
       "2      8810528         B                    0                        B\n",
       "3       905978         B                    0                        B\n",
       "4    871001502         B                    0                        B\n",
       "5        87880         M                    1                        M\n",
       "6       882488         B                    0                        B\n",
       "7    911296202         M                    1                        M\n",
       "8       861648         B                    0                        B\n",
       "9       895100         M                    1                        M\n",
       "10      853612         M                    1                        M\n",
       "11     8510653         B                    0                        B\n",
       "12    88466802         B                    0                        B\n",
       "13      911150         B                    1                        M\n",
       "14     9110944         B                    0                        B\n",
       "15     9113156         B                    0                        B\n",
       "16      859711         B                    0                        B\n",
       "17     9013579         B                    1                        M\n",
       "18    86973701         B                    0                        B\n",
       "19    85638502         M                    1                        M"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at Actual and Predicted Diagnosis together:\n",
    "\n",
    "\n",
    "results_binary_classifier = pd.concat([test[['Patient_ID','Diagnosis']],predicted_L2, predicted_L2_df],axis =1)\n",
    "\n",
    "print(\"       Logistic L2 Classifier Predictions:\")\n",
    "results_binary_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic L2 Classifier Evaluation Metrics:\n",
      "\n",
      "Accuracy Score is: 0.85\n",
      "Precision Score is: 0.7142857142857143\n",
      "Recall Score is: 0.8333333333333334\n",
      "F1-Score is: 0.7692307692307692\n",
      "Confusion Matrix is:\n",
      " [[12  2]\n",
      " [ 1  5]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic L2 Classifier Evaluation Metrics:\\n\")\n",
    "print(\"Accuracy Score is:\",accuracy_score((Y_test_le), Series(logistic_binary_classifier_L2.predict(X_test))))\n",
    "print(\"Precision Score is:\",precision_score((Y_test_le), Series(logistic_binary_classifier_L2.predict(X_test))))\n",
    "print(\"Recall Score is:\",recall_score((Y_test_le), Series(logistic_binary_classifier_L2.predict(X_test))))\n",
    "print(\"F1-Score is:\",f1_score((Y_test_le), logistic_binary_classifier_L2.predict(X_test)))\n",
    "print(\"Confusion Matrix is:\\n\",confusion_matrix((Y_test_le), Series(logistic_binary_classifier_L2.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 1.3 Choosing the best hyper-parameter\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric selected: accuracy\n"
     ]
    }
   ],
   "source": [
    "# My student Id is: \n",
    "\n",
    "student_id = 216337197\n",
    "\n",
    "if (student_id % 3) == 0 : \n",
    "    metric = 'accuracy'\n",
    "elif student_id % 3 == 1: \n",
    "    metric = 'f1_score'\n",
    "elif student_id % 3 == 2: \n",
    "    metric = 'precision'\n",
    "\n",
    "print(\"metric selected:\",metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use: gridsearchCV, K-fold Cross Validation, and pipelining to do task 1.3\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "#simplefilter(action='ignore', category=[FutureWarning])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0   Alpha value: 0.1\n",
      "Accuracy Score is: 0.8333333333333334\n",
      "Accuracy Score is: 0.8666666666666667\n",
      "Accuracy Score is: 0.8666666666666667\n",
      "Accuracy Score is: 0.9\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.8\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Scores for Model: 0 \n",
      " [0.8333333333333334, 0.8666666666666667, 0.8666666666666667, 0.9, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.8, 0.9333333333333333] \n",
      "\n",
      "Model: 1   Alpha value: 1\n",
      "Accuracy Score is: 0.9\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 0.9\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 0.9\n",
      "Accuracy Scores for Model: 1 \n",
      " [0.9, 0.9333333333333333, 0.9, 0.9333333333333333, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9] \n",
      "\n",
      "Model: 2   Alpha value: 3\n",
      "Accuracy Score is: 0.9\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 0.9\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Scores for Model: 2 \n",
      " [0.9, 1.0, 0.9, 0.9333333333333333, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333] \n",
      "\n",
      "Model: 3   Alpha value: 10\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Scores for Model: 3 \n",
      " [0.9333333333333333, 1.0, 0.9333333333333333, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9, 0.9666666666666667, 0.9666666666666667] \n",
      "\n",
      "Model: 4   Alpha value: 33\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 0.9\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Scores for Model: 4 \n",
      " [0.9333333333333333, 1.0, 0.9, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9, 0.9666666666666667, 0.9666666666666667] \n",
      "\n",
      "Model: 5   Alpha value: 100\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Scores for Model: 5 \n",
      " [0.9333333333333333, 1.0, 0.9333333333333333, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9, 0.9666666666666667, 0.9666666666666667] \n",
      "\n",
      "Model: 6   Alpha value: 333\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Scores for Model: 6 \n",
      " [0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 1.0, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333] \n",
      "\n",
      "Model: 7   Alpha value: 1000\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Scores for Model: 7 \n",
      " [0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 1.0, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333] \n",
      "\n",
      "Model: 8   Alpha value: 3333\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9\n",
      "Accuracy Scores for Model: 8 \n",
      " [0.9666666666666667, 0.9, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9] \n",
      "\n",
      "Model: 9   Alpha value: 10000\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 0.9\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9333333333333333\n",
      "Accuracy Score is: 0.8333333333333334\n",
      "Accuracy Scores for Model: 9 \n",
      " [0.9666666666666667, 0.9, 1.0, 0.9, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9333333333333333, 0.8333333333333334] \n",
      "\n",
      "Model: 10   Alpha value: 33333\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 0.9\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 1.0\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9666666666666667\n",
      "Accuracy Score is: 0.9\n",
      "Accuracy Scores for Model: 10 \n",
      " [0.9666666666666667, 0.9666666666666667, 1.0, 0.9, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9] \n",
      "\n",
      "     Model0    Model1    Model2    Model3    Model4    Model5    Model6  \\\n",
      "0  0.833333  0.900000  0.900000  0.933333  0.933333  0.933333  0.933333   \n",
      "1  0.866667  0.933333  1.000000  1.000000  1.000000  1.000000  0.933333   \n",
      "2  0.866667  0.900000  0.900000  0.933333  0.900000  0.933333  0.966667   \n",
      "3  0.900000  0.933333  0.933333  0.966667  0.966667  0.966667  1.000000   \n",
      "4  0.933333  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
      "5  0.966667  0.966667  0.966667  0.966667  0.966667  0.933333  0.933333   \n",
      "6  0.966667  0.966667  0.966667  0.966667  0.966667  0.966667  0.966667   \n",
      "7  0.966667  0.966667  0.966667  0.900000  0.900000  0.900000  0.933333   \n",
      "8  0.800000  0.933333  0.966667  0.966667  0.966667  0.966667  0.966667   \n",
      "9  0.933333  0.900000  0.933333  0.966667  0.966667  0.966667  0.933333   \n",
      "\n",
      "     Model7    Model8    Model9   Model10  \n",
      "0  0.966667  0.966667  0.966667  0.966667  \n",
      "1  0.933333  0.900000  0.900000  0.966667  \n",
      "2  0.966667  0.966667  1.000000  1.000000  \n",
      "3  1.000000  1.000000  0.900000  0.900000  \n",
      "4  1.000000  0.966667  1.000000  1.000000  \n",
      "5  0.933333  0.966667  1.000000  1.000000  \n",
      "6  0.966667  0.933333  1.000000  1.000000  \n",
      "7  0.933333  0.966667  0.966667  0.966667  \n",
      "8  0.966667  0.966667  0.933333  0.966667  \n",
      "9  0.933333  0.900000  0.833333  0.900000   \n",
      "\n",
      "Mean Accuracy of Models:\n",
      " Model0     0.903333\n",
      "Model1     0.940000\n",
      "Model2     0.953333\n",
      "Model3     0.960000\n",
      "Model4     0.956667\n",
      "Model5     0.956667\n",
      "Model6     0.956667\n",
      "Model7     0.960000\n",
      "Model8     0.953333\n",
      "Model9     0.950000\n",
      "Model10    0.966667\n",
      "dtype: float64 \n",
      "\n",
      "Model with highest accuracy score =  0.9666666666666668  is: Model10 \n",
      "And It has Alpha value = 33333\n",
      "final alpha: 33333\n"
     ]
    }
   ],
   "source": [
    "# Defining L1 Logistic Model and values for alpha parameter:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#L1_model = LogisticRegression(penalty = 'l1')\n",
    "\n",
    "#alpha_list = {'C':[0.1,1,3,10,33,100,333,1000,3333,10000,33333]}\n",
    "#lambda_list = {'C':[0.001,0.003,0.01,0.03,0.1,0.3,1,3,10,33]}\n",
    "\n",
    "alpha_list  = [0.1,1,3,10,33,100,333,1000,3333,10000,33333]\n",
    "\n",
    "# Performing 10 random splits of the training dataset: \n",
    "\n",
    "# Using a For loop for this:\n",
    "\n",
    "accuracy_matrix  = pd.DataFrame()\n",
    "\n",
    "for p in range(len(alpha_list)):\n",
    "    #len(alpha_list)\n",
    "    \n",
    "    precision_score_list = []\n",
    "    \n",
    "    precision_score_list.append(alpha_list[p])\n",
    "    \n",
    "    print(\"Model:\",p,\"  Alpha value:\",alpha_list[p])\n",
    "    \n",
    "    accuracy_score_model = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        X_train_new, X_validate, Y_train_new, Y_validate = train_test_split(X_train, Y_train, test_size=0.3, random_state=i)\n",
    "        X_train_new.shape, X_validate.shape, Y_train_new.shape, Y_validate.shape\n",
    "        #Label Encoder:\n",
    "        Y_train_new_le = le.fit_transform(Y_train_new)\n",
    "        Y_validate_le = le.fit_transform(Y_validate)\n",
    "        \n",
    "        L1_model = LogisticRegression(penalty = 'l1', C = alpha_list[p], solver = 'liblinear', max_iter = 500)\n",
    "        L1_model.fit(X_train_new, Y_train_new_le)\n",
    "        L1_model.predict(X_validate)\n",
    "        \n",
    "        from sklearn.metrics import accuracy_score as acc\n",
    "        from sklearn.metrics import precision_score as pr\n",
    "        from sklearn.metrics import confusion_matrix as cm\n",
    "        \n",
    "        print(\"Accuracy Score is:\",acc((Y_validate_le), Series(L1_model.predict(X_validate))))\n",
    "        \n",
    "        accuracy = acc((Y_validate_le), Series(L1_model.predict(X_validate)))\n",
    "        accuracy_score_model.append(accuracy)\n",
    "\n",
    "        \n",
    "        \n",
    "    print(\"Accuracy Scores for Model:\",p, \"\\n\",accuracy_score_model , \"\\n\")\n",
    "    accuracy_matrix = pd.concat([accuracy_matrix, DataFrame(accuracy_score_model, columns = [\"Model%s\" % (p)])],  axis=1)\n",
    "    \n",
    "print((accuracy_matrix),\"\\n\")\n",
    "print(\"Mean Accuracy of Models:\\n\",accuracy_matrix.mean(),\"\\n\")\n",
    "\n",
    "best_alpha_index = int(str(accuracy_matrix.mean().idxmax())[5:])\n",
    "final_alpha = alpha_list[best_alpha_index]\n",
    "\n",
    "print(\"Model with highest accuracy score = \",accuracy_matrix.mean().max(), \" is:\",accuracy_matrix.mean().idxmax(),\n",
    "     \"\\nAnd It has Alpha value =\",alpha_list[best_alpha_index])\n",
    "\n",
    "print(\"final alpha:\",final_alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [[-4.58806745e-01  3.60787471e-01 -4.15539127e-02  7.77335700e-03\n",
      "  -1.29622662e+02  2.39666396e+00  1.24873814e+02  1.24649570e+02\n",
      "   0.00000000e+00 -2.83732296e+02 -2.20070420e+01 -2.91610899e+00\n",
      "   2.12393990e-01  3.92056399e-01  1.03104543e+02  1.93686488e+01\n",
      "  -3.29233946e+02  0.00000000e+00 -3.19686826e+02  0.00000000e+00\n",
      "  -1.01034075e-01  7.86517115e-01 -7.04989535e-03  1.59296648e-02\n",
      "   2.49177378e+00  3.19096566e+01 -5.99393252e+00  1.45342597e+01\n",
      "   1.80652417e+01 -2.19744970e+01]]\n",
      "\n",
      " [-18.46083143] \n",
      "\n",
      "(100, 27) \n",
      "\n",
      "Accuracy =  0.85       Precision =  0.7142857142857143        \n",
      "Confusion Matrix = \n",
      " [[12  2]\n",
      " [ 1  5]]\n",
      "\n",
      " Top5 Features and their weights are (index represrnt f1 - f30:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>124.873814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>124.649570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>103.104543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>31.909657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19.368649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_weights\n",
       "6        124.873814\n",
       "7        124.649570\n",
       "14       103.104543\n",
       "25        31.909657\n",
       "15        19.368649"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-training the best L1 model:\n",
    "\n",
    "\n",
    "L1_model = LogisticRegression(penalty = 'l1', C = final_alpha, solver = 'liblinear', max_iter = 500)\n",
    "L1_model.fit(X_train, Y_train_le)\n",
    "L1_model.predict(X_test)\n",
    "\n",
    "print(\"\\n\",L1_model.coef_), print(\"\\n\",L1_model.intercept_,\"\\n\")\n",
    "\n",
    "accuracy = acc((Y_test_le), Series(L1_model.predict(X_test)))\n",
    "precision = pr((Y_test_le), Series(L1_model.predict(X_test)))\n",
    "confusion_m = confusion_matrix((Y_test_le), Series(L1_model.predict(X_test)))\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "model = SelectFromModel(L1_model, prefit=True)\n",
    "model_new = model.transform(X_train)\n",
    "print(model_new.shape, \"\\n\")\n",
    "\n",
    "#model_2_new = SelectKBest(k=5).fit_transform(X_train, Y_train_le)\n",
    "#print(model_2_new.shape), print(model_2_new)\n",
    "\n",
    "print(\"Accuracy = \",accuracy, \"      Precision = \",precision, \"       \\nConfusion Matrix = \\n\",confusion_m)\n",
    "\n",
    "# Top 5 Features in dec order:\n",
    "\n",
    "all_features = DataFrame(L1_model.coef_).max()\n",
    "feature_weights = DataFrame(all_features, columns = ['feature_weights'])\n",
    "feature_weights.sort_values('feature_weights',ascending = False, inplace =True)\n",
    "\n",
    "# Top5 Features and their weights:\n",
    "\n",
    "print(\"\\n Top5 Features and their weights are (index represrnt f1 - f30:\")\n",
    "feature_weights.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0   Lambda value: 0.001\n",
      "Accuracy Scores for Model: 0 \n",
      " [0.8666666666666667, 0.8666666666666667, 0.9, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.8333333333333334, 0.9666666666666667] \n",
      "\n",
      "Model: 1   Lambda value: 0.003\n",
      "Accuracy Scores for Model: 1 \n",
      " [0.8666666666666667, 0.9333333333333333, 0.9, 0.9333333333333333, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.8666666666666667, 0.9666666666666667] \n",
      "\n",
      "Model: 2   Lambda value: 0.01\n",
      "Accuracy Scores for Model: 2 \n",
      " [0.9, 0.9333333333333333, 0.9, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667] \n",
      "\n",
      "Model: 3   Lambda value: 0.03\n",
      "Accuracy Scores for Model: 3 \n",
      " [0.9, 0.9666666666666667, 0.9, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 1.0] \n",
      "\n",
      "Model: 4   Lambda value: 0.1\n",
      "Accuracy Scores for Model: 4 \n",
      " [0.9, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667] \n",
      "\n",
      "Model: 5   Lambda value: 0.3\n",
      "Accuracy Scores for Model: 5 \n",
      " [0.9, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667] \n",
      "\n",
      "Model: 6   Lambda value: 1\n",
      "Accuracy Scores for Model: 6 \n",
      " [0.9, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667] \n",
      "\n",
      "Model: 7   Lambda value: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for Model: 7 \n",
      " [0.9, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333] \n",
      "\n",
      "Model: 8   Lambda value: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for Model: 8 \n",
      " [0.9, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333] \n",
      "\n",
      "Model: 9   Lambda value: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for Model: 9 \n",
      " [0.9, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333] \n",
      "\n",
      "     Model0    Model1    Model2    Model3    Model4    Model5    Model6  \\\n",
      "0  0.866667  0.866667  0.900000  0.900000  0.900000  0.900000  0.900000   \n",
      "1  0.866667  0.933333  0.933333  0.966667  0.966667  1.000000  1.000000   \n",
      "2  0.900000  0.900000  0.900000  0.900000  0.966667  0.966667  0.966667   \n",
      "3  0.966667  0.933333  0.966667  0.966667  0.966667  0.966667  0.966667   \n",
      "4  0.966667  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
      "5  0.933333  0.966667  0.966667  0.966667  0.933333  0.933333  0.933333   \n",
      "6  0.966667  0.966667  0.966667  0.966667  0.933333  0.933333  0.933333   \n",
      "7  0.966667  0.966667  0.966667  0.966667  0.933333  0.933333  0.933333   \n",
      "8  0.833333  0.866667  0.933333  0.933333  0.933333  0.966667  0.966667   \n",
      "9  0.966667  0.966667  0.966667  1.000000  0.966667  0.966667  0.966667   \n",
      "\n",
      "     Model7    Model8    Model9  \n",
      "0  0.900000  0.900000  0.900000  \n",
      "1  1.000000  1.000000  1.000000  \n",
      "2  0.966667  0.966667  0.966667  \n",
      "3  0.966667  0.966667  0.966667  \n",
      "4  1.000000  1.000000  1.000000  \n",
      "5  0.933333  0.933333  0.933333  \n",
      "6  0.933333  0.933333  0.933333  \n",
      "7  0.933333  0.933333  0.933333  \n",
      "8  0.966667  0.966667  0.966667  \n",
      "9  0.933333  0.933333  0.933333   \n",
      "\n",
      "Mean Accuracy of Models:\n",
      " Model0    0.923333\n",
      "Model1    0.936667\n",
      "Model2    0.950000\n",
      "Model3    0.956667\n",
      "Model4    0.950000\n",
      "Model5    0.956667\n",
      "Model6    0.956667\n",
      "Model7    0.953333\n",
      "Model8    0.953333\n",
      "Model9    0.953333\n",
      "dtype: float64 \n",
      "\n",
      "Model with highest accuracy score =  0.9566666666666668  is: Model5 \n",
      "And It has Lambda value = 0.3\n",
      "final lambda: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Defining L2 Logistic Model and values for lambda parameter:\n",
    "\n",
    "L2_model = LogisticRegression(penalty = 'l2')\n",
    "\n",
    "#lambda_list = {'C':[0.001,0.003,0.01,0.03,0.1,0.3,1,3,10,33]}\n",
    "\n",
    "lambda_list  = [0.001,0.003,0.01,0.03,0.1,0.3,1,3,10,33]\n",
    "\n",
    "# Performing 10 random splits of the training dataset: \n",
    "\n",
    "# Using a For loop for this:\n",
    "\n",
    "accuracy_matrix  = pd.DataFrame()\n",
    "\n",
    "for p in range(len(lambda_list)):\n",
    "    #len(lambda_list)\n",
    "    \n",
    "    precision_score_list = []\n",
    "    \n",
    "    precision_score_list.append(lambda_list[p])\n",
    "    \n",
    "    print(\"Model:\",p,\"  Lambda value:\",lambda_list[p])\n",
    "    \n",
    "    accuracy_score_model = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        X_train_new, X_validate, Y_train_new, Y_validate = train_test_split(X_train, Y_train, test_size=0.3, random_state=i)\n",
    "        X_train_new.shape, X_validate.shape, Y_train_new.shape, Y_validate.shape\n",
    "        #Label Encoder:\n",
    "        Y_train_new_le = le.fit_transform(Y_train_new)\n",
    "        Y_validate_le = le.fit_transform(Y_validate)\n",
    "\n",
    "        L1_model = LogisticRegression(penalty = 'l2', C = lambda_list[p], solver = 'lbfgs', max_iter = 1500)\n",
    "        L1_model.fit(X_train_new, Y_train_new_le)\n",
    "        L1_model.predict(X_validate)\n",
    "        \n",
    "        from sklearn.metrics import accuracy_score as acc\n",
    "        from sklearn.metrics import precision_score as pr\n",
    "        from sklearn.metrics import confusion_matrix as cm\n",
    "        \n",
    "        #print(\"Accuracy Score is:\",acc((Y_validate_le), Series(L1_model.predict(X_validate))))\n",
    "        \n",
    "        accuracy = acc((Y_validate_le), Series(L1_model.predict(X_validate)))\n",
    "        accuracy_score_model.append(accuracy)\n",
    "        \n",
    "    print(\"Accuracy Scores for Model:\",p, \"\\n\",accuracy_score_model , \"\\n\")\n",
    "    accuracy_matrix = pd.concat([accuracy_matrix, DataFrame(accuracy_score_model, columns = [\"Model%s\" % (p)])],  axis=1)\n",
    "    \n",
    "print((accuracy_matrix),\"\\n\")\n",
    "print(\"Mean Accuracy of Models:\\n\",accuracy_matrix.mean(),\"\\n\")\n",
    "\n",
    "best_lambda_index = int(str(accuracy_matrix.mean().idxmax())[5:])\n",
    "final_lambda = lambda_list[best_lambda_index]\n",
    "\n",
    "print(\"Model with highest accuracy score = \",accuracy_matrix.mean().max(), \" is:\",accuracy_matrix.mean().idxmax(),\n",
    "     \"\\nAnd It has Lambda value =\",lambda_list[best_lambda_index])\n",
    "\n",
    "print(\"final lambda:\",final_lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Model with Final Labmda:  0.3\n",
      "\n",
      " [[-0.50906374 -0.13122465 -0.61450826  0.02798386  0.01186438  0.06371997\n",
      "   0.08490956  0.0345213   0.01872547  0.00202393 -0.02377701 -0.07962243\n",
      "   0.09398755 -0.0684455   0.00122445  0.01469389  0.01953694  0.00443454\n",
      "   0.00110594  0.00155759 -0.4831642   0.41077285  0.2880612   0.02109317\n",
      "   0.01955563  0.1785694   0.21158239  0.0585415   0.03523038  0.01413385]]\n",
      "\n",
      " [-0.07346913] \n",
      "\n",
      "(100, 8) \n",
      "\n",
      "Accuracy =  0.85       Precision =  0.7142857142857143        \n",
      "Confusion Matrix = \n",
      " [[12  2]\n",
      " [ 1  5]]\n",
      "\n",
      " Top5 Features and their weights are (index represent f1 - f30:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.410773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.288061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.211582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.178569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.093988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_weights\n",
       "21         0.410773\n",
       "22         0.288061\n",
       "26         0.211582\n",
       "25         0.178569\n",
       "12         0.093988"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-training the best L2 model:\n",
    "\n",
    "print(\"L2 Model with Final Labmda: \", final_lambda)\n",
    "\n",
    "L2_model = LogisticRegression(penalty = 'l2', C = final_lambda)\n",
    "L2_model.fit(X_train, Y_train_le)\n",
    "L2_model.predict(X_test)\n",
    "\n",
    "print(\"\\n\",L2_model.coef_), print(\"\\n\",L2_model.intercept_,\"\\n\")\n",
    "\n",
    "accuracy = acc((Y_test_le), Series(L2_model.predict(X_test)))\n",
    "precision = pr((Y_test_le), Series(L2_model.predict(X_test)))\n",
    "confusion_m = confusion_matrix((Y_test_le), Series(L2_model.predict(X_test)))\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "model = SelectFromModel(L2_model, prefit=True)\n",
    "model_new = model.transform(X_train)\n",
    "print(model_new.shape, \"\\n\")\n",
    "\n",
    "#model_2_new = SelectKBest(k=5).fit_transform(X_train, Y_train_le)\n",
    "#print(model_2_new.shape), print(model_2_new)\n",
    "\n",
    "print(\"Accuracy = \",accuracy, \"      Precision = \",precision, \"       \\nConfusion Matrix = \\n\",confusion_m)\n",
    "\n",
    "# Top 5 Features in dec order:\n",
    "\n",
    "all_features = DataFrame(L2_model.coef_).max()\n",
    "feature_weights = DataFrame(all_features, columns = ['feature_weights'])\n",
    "feature_weights.sort_values('feature_weights',ascending = False, inplace =True)\n",
    "\n",
    "# Top5 Features and their weights:\n",
    "\n",
    "print(\"\\n Top5 Features and their weights are (index represent f1 - f30:\")\n",
    "feature_weights.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "##Part2: Multi-Class Classification \n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the MSSIT dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      2       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = pd.read_csv(\"reduced_mnist.csv\")\n",
    "\n",
    "mnist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2520, 785)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Data Points =  2520      No of Features =  785\n"
     ]
    }
   ],
   "source": [
    "print(\"No of Data Points = \",mnist.shape[0], \"     No of Features = \", mnist.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([1, 2, 3, 0, 7, 6, 4, 8, 9, 5], dtype='int64')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "1    286\n",
       "2    269\n",
       "3    258\n",
       "0    257\n",
       "7    256\n",
       "6    243\n",
       "4    243\n",
       "8    239\n",
       "9    238\n",
       "5    231"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique Labels in the dataset:\n",
    "print(DataFrame(mnist['label'].value_counts()).index)\n",
    "\n",
    "# Unique Labels and thier counts:\n",
    "DataFrame(mnist['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1764, 784), (1764,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data into train and test:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(mnist.iloc[:,1:], mnist['label'], test_size=0.3, random_state=1)\n",
    "\n",
    "X_train.shape, Y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "          n_jobs=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the L1 with alpha = 1 logistic regression one vs rest classifier:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "#Y_train =Y_train.as_matrix().reshape(-1,1)\n",
    "\n",
    "#Y_train_enc = enc.fit(Y_train)\n",
    "\n",
    "#Y_train_enc = enc.fit_transform(Y_train).toarray()\n",
    "\n",
    "l1_mnist = LogisticRegression(penalty = 'l1', C = 1)\n",
    "one_vs_rest = OneVsRestClassifier(l1_mnist)\n",
    "\n",
    "# Fitting the One vs Rest Logistic Regression:\n",
    "\n",
    "logistic_one_vs = one_vs_rest.fit(X_train,Y_train)\n",
    "logistic_one_vs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[168   0   0   0   0   0   0   0   0   0]\n",
      " [  0 209   0   0   0   0   0   0   0   0]\n",
      " [  0   0 186   0   0   0   0   0   0   0]\n",
      " [  0   0   0 176   0   0   0   0   0   0]\n",
      " [  0   0   0   0 165   0   0   0   0   0]\n",
      " [  0   0   0   0   0 166   0   0   0   0]\n",
      " [  0   0   0   0   0   0 172   0   0   0]\n",
      " [  0   0   0   0   0   0   0 182   0   0]\n",
      " [  0   0   0   0   0   0   0   0 182   0]\n",
      " [  0   0   0   0   0   0   0   0   0 158]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Model performance on training Data:\n",
    "\n",
    "logistic_one_vs.predict(X_train)\n",
    "accuracy = acc((Y_train), Series(logistic_one_vs.predict(X_train)))\n",
    "accuracy\n",
    "\n",
    "Y_train.head(), Series(logistic_one_vs.predict(X_train)).head()\n",
    "\n",
    "confusion = cm(Series(Y_train), Series(logistic_one_vs.predict(X_train)))\n",
    "\n",
    "print (accuracy)\n",
    "print(confusion)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8201058201058201 \n",
      "Precision = Precision cant be computed for one-vs-rest classification \n",
      "Recall = Recall cant be computed for one-vs-rest classification        \n",
      "\n",
      "Confusion Matrix = \n",
      " [[83  0  1  0  0  1  1  0  3  0]\n",
      " [ 0 74  1  0  0  0  0  0  2  0]\n",
      " [ 2  3 59  2  1  1  2  3  9  1]\n",
      " [ 0  1  4 64  1  7  0  0  4  1]\n",
      " [ 1  0  1  0 61  1  4  2  5  3]\n",
      " [ 1  1  1  5  1 43  3  0  8  2]\n",
      " [ 0  0  1  0  0  1 69  0  0  0]\n",
      " [ 0  0  2  0  2  0  0 65  2  3]\n",
      " [ 1  3  2  3  0  2  1  0 42  3]\n",
      " [ 1  0  2  3  9  0  0  5  0 60]]\n"
     ]
    }
   ],
   "source": [
    "# Reporting Accuracy, Precision, Recall and Confusion Matrix:\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import precision_score as pr\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.metrics import recall_score as recall\n",
    "\n",
    "accuracy = acc((Y_test), Series(logistic_one_vs.predict(X_test)))\n",
    "#precision = pr((Y_test), Series(logistic_one_vs.predict(X_test)))\n",
    "#recall = recall((Y_test), Series(logistic_one_vs.predict(X_test)))\n",
    "confusion_m = confusion_matrix((Y_test), Series(logistic_one_vs.predict(X_test)))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Accuracy = \",accuracy, \"\\nPrecision = Precision cant be computed for one-vs-rest classification\"  , \n",
    "      \"\\nRecall = Recall cant be computed for one-vs-rest classification\",\"       \\n\\nConfusion Matrix = \\n\",confusion_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0   Alpha value: 0.1\n",
      "Validation Accuracy Scores for Model: 0 \n",
      " [0.8509433962264151, 0.8509433962264151, 0.8283018867924529, 0.8301886792452831, 0.8339622641509434, 0.8622641509433963, 0.8584905660377359, 0.839622641509434, 0.8528301886792453, 0.8528301886792453] \n",
      "\n",
      "Training Scores for Model: 0 \n",
      " [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
      "\n",
      "Model: 1   Alpha value: 1\n",
      "Validation Accuracy Scores for Model: 1 \n",
      " [0.8415094339622642, 0.8509433962264151, 0.8358490566037736, 0.8433962264150944, 0.8471698113207548, 0.8622641509433963, 0.8660377358490566, 0.839622641509434, 0.8547169811320755, 0.8660377358490566] \n",
      "\n",
      "Training Scores for Model: 1 \n",
      " [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
      "\n",
      "Model: 2   Alpha value: 3\n",
      "Validation Accuracy Scores for Model: 2 \n",
      " [0.8622641509433963, 0.8584905660377359, 0.8415094339622642, 0.8415094339622642, 0.8509433962264151, 0.869811320754717, 0.8716981132075472, 0.8358490566037736, 0.8584905660377359, 0.8660377358490566] \n",
      "\n",
      "Training Scores for Model: 2 \n",
      " [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
      "\n",
      "Model: 3   Alpha value: 10\n",
      "Validation Accuracy Scores for Model: 3 \n",
      " [0.8547169811320755, 0.8547169811320755, 0.8641509433962264, 0.8283018867924529, 0.8452830188679246, 0.8584905660377359, 0.8716981132075472, 0.8301886792452831, 0.8566037735849057, 0.8603773584905661] \n",
      "\n",
      "Training Scores for Model: 3 \n",
      " [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
      "\n",
      "Model: 4   Alpha value: 33\n",
      "Validation Accuracy Scores for Model: 4 \n",
      " [0.8528301886792453, 0.8509433962264151, 0.8433962264150944, 0.8547169811320755, 0.8452830188679246, 0.8622641509433963, 0.8660377358490566, 0.8339622641509434, 0.8471698113207548, 0.8679245283018868] \n",
      "\n",
      "Training Scores for Model: 4 \n",
      " [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
      "\n",
      "Model: 5   Alpha value: 100\n",
      "Validation Accuracy Scores for Model: 5 \n",
      " [0.8452830188679246, 0.8452830188679246, 0.8452830188679246, 0.8283018867924529, 0.839622641509434, 0.8490566037735849, 0.8584905660377359, 0.8320754716981132, 0.8452830188679246, 0.8509433962264151] \n",
      "\n",
      "Training Scores for Model: 5 \n",
      " [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
      "\n",
      "Model: 6   Alpha value: 333\n",
      "Validation Accuracy Scores for Model: 6 \n",
      " [0.8528301886792453, 0.8452830188679246, 0.8433962264150944, 0.8377358490566038, 0.8339622641509434, 0.8471698113207548, 0.8603773584905661, 0.8339622641509434, 0.8415094339622642, 0.8490566037735849] \n",
      "\n",
      "Training Scores for Model: 6 \n",
      " [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
      "\n",
      "Model: 7   Alpha value: 1000\n",
      "Validation Accuracy Scores for Model: 7 \n",
      " [0.8433962264150944, 0.8490566037735849, 0.8377358490566038, 0.8301886792452831, 0.839622641509434, 0.8433962264150944, 0.8471698113207548, 0.8207547169811321, 0.8433962264150944, 0.8471698113207548] \n",
      "\n",
      "Training Scores for Model: 7 \n",
      " [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
      "\n",
      "Model: 8   Alpha value: 3333\n",
      "Validation Accuracy Scores for Model: 8 \n",
      " [0.8358490566037736, 0.8452830188679246, 0.8433962264150944, 0.8339622641509434, 0.8377358490566038, 0.8358490566037736, 0.8603773584905661, 0.8207547169811321, 0.8377358490566038, 0.8490566037735849] \n",
      "\n",
      "Training Scores for Model: 8 \n",
      " [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
      "\n",
      "Model: 9   Alpha value: 10000\n",
      "Validation Accuracy Scores for Model: 9 \n",
      " [0.8433962264150944, 0.8377358490566038, 0.8415094339622642, 0.8283018867924529, 0.8207547169811321, 0.8377358490566038, 0.8452830188679246, 0.8169811320754717, 0.8377358490566038, 0.8358490566037736] \n",
      "\n",
      "Training Scores for Model: 9 \n",
      " [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
      "\n",
      "Model: 10   Alpha value: 33333\n",
      "Validation Accuracy Scores for Model: 10 \n",
      " [0.8283018867924529, 0.8339622641509434, 0.8283018867924529, 0.8245283018867925, 0.8283018867924529, 0.8415094339622642, 0.8528301886792453, 0.8226415094339623, 0.8301886792452831, 0.8471698113207548] \n",
      "\n",
      "Training Scores for Model: 10 \n",
      " [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
      "\n",
      "     Model0    Model1    Model2    Model3    Model4    Model5    Model6  \\\n",
      "0  0.850943  0.841509  0.862264  0.854717  0.852830  0.845283  0.852830   \n",
      "1  0.850943  0.850943  0.858491  0.854717  0.850943  0.845283  0.845283   \n",
      "2  0.828302  0.835849  0.841509  0.864151  0.843396  0.845283  0.843396   \n",
      "3  0.830189  0.843396  0.841509  0.828302  0.854717  0.828302  0.837736   \n",
      "4  0.833962  0.847170  0.850943  0.845283  0.845283  0.839623  0.833962   \n",
      "5  0.862264  0.862264  0.869811  0.858491  0.862264  0.849057  0.847170   \n",
      "6  0.858491  0.866038  0.871698  0.871698  0.866038  0.858491  0.860377   \n",
      "7  0.839623  0.839623  0.835849  0.830189  0.833962  0.832075  0.833962   \n",
      "8  0.852830  0.854717  0.858491  0.856604  0.847170  0.845283  0.841509   \n",
      "9  0.852830  0.866038  0.866038  0.860377  0.867925  0.850943  0.849057   \n",
      "\n",
      "     Model7    Model8    Model9   Model10  \n",
      "0  0.843396  0.835849  0.843396  0.828302  \n",
      "1  0.849057  0.845283  0.837736  0.833962  \n",
      "2  0.837736  0.843396  0.841509  0.828302  \n",
      "3  0.830189  0.833962  0.828302  0.824528  \n",
      "4  0.839623  0.837736  0.820755  0.828302  \n",
      "5  0.843396  0.835849  0.837736  0.841509  \n",
      "6  0.847170  0.860377  0.845283  0.852830  \n",
      "7  0.820755  0.820755  0.816981  0.822642  \n",
      "8  0.843396  0.837736  0.837736  0.830189  \n",
      "9  0.847170  0.849057  0.835849  0.847170   \n",
      "\n",
      "Mean Validation Accuracy of Models:\n",
      " Model0     0.846038\n",
      "Model1     0.850755\n",
      "Model2     0.855660\n",
      "Model3     0.852453\n",
      "Model4     0.852453\n",
      "Model5     0.843962\n",
      "Model6     0.844528\n",
      "Model7     0.840189\n",
      "Model8     0.840000\n",
      "Model9     0.834528\n",
      "Model10    0.833774\n",
      "dtype: float64 \n",
      "\n",
      "   Model0  Model1  Model2  Model3  Model4  Model5  Model6  Model7  Model8  \\\n",
      "0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
      "1     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
      "2     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
      "3     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
      "4     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
      "5     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
      "6     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
      "7     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
      "8     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
      "9     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
      "\n",
      "   Model9  Model10  \n",
      "0     1.0      1.0  \n",
      "1     1.0      1.0  \n",
      "2     1.0      1.0  \n",
      "3     1.0      1.0  \n",
      "4     1.0      1.0  \n",
      "5     1.0      1.0  \n",
      "6     1.0      1.0  \n",
      "7     1.0      1.0  \n",
      "8     1.0      1.0  \n",
      "9     1.0      1.0   \n",
      "\n",
      "Mean Training Accuracy of Models:\n",
      " Model0     1.0\n",
      "Model1     1.0\n",
      "Model2     1.0\n",
      "Model3     1.0\n",
      "Model4     1.0\n",
      "Model5     1.0\n",
      "Model6     1.0\n",
      "Model7     1.0\n",
      "Model8     1.0\n",
      "Model9     1.0\n",
      "Model10    1.0\n",
      "dtype: float64 \n",
      "\n",
      "Overall Training Accuracy of Models:\n",
      " Model0     1.846038\n",
      "Model1     1.850755\n",
      "Model2     1.855660\n",
      "Model3     1.852453\n",
      "Model4     1.852453\n",
      "Model5     1.843962\n",
      "Model6     1.844528\n",
      "Model7     1.840189\n",
      "Model8     1.840000\n",
      "Model9     1.834528\n",
      "Model10    1.833774\n",
      "dtype: float64 \n",
      "\n",
      "Model with highest Overall accuracy score =  1.855660377358491  is: Model2 \n",
      "And It has Alpha value = 33333\n",
      "final alpha: 33333\n"
     ]
    }
   ],
   "source": [
    "# Part 2.2 Choosing the best alpha value: will use accuracy as per by student ID caluclation of metric fID = SID %3\n",
    "\n",
    "# Defining L1 Logistic Model and values for alpha parameter:\n",
    "#L1_model = LogisticRegression(penalty = 'l1')\n",
    "\n",
    "alpha_list  = [0.1,1,3,10,33,100,333,1000,3333,10000,33333]\n",
    "\n",
    "# Performing 10 random splits of the training dataset: \n",
    "\n",
    "# Using a For loop for this:\n",
    "\n",
    "validation_accuracy_matrix  = pd.DataFrame()\n",
    "training_accuracy_matrix  = pd.DataFrame()\n",
    "\n",
    "for p in range(len(alpha_list)):\n",
    "    #len(alpha_list)\n",
    "    \n",
    "    precision_score_list = []\n",
    "    \n",
    "    precision_score_list.append(alpha_list[p])\n",
    "    \n",
    "    print(\"Model:\",p,\"  Alpha value:\",alpha_list[p])\n",
    "    \n",
    "    validation_accuracy_score_model = []\n",
    "    training_accuracy_score_model = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        X_train_new, X_validate, Y_train_new, Y_validate = train_test_split(X_train, Y_train, test_size=0.3, random_state=i)\n",
    "        X_train_new.shape, X_validate.shape, Y_train_new.shape, Y_validate.shape\n",
    "        #Label Encoder:\n",
    "        Y_train_new_le = le.fit_transform(Y_train_new)\n",
    "        Y_validate_le = le.fit_transform(Y_validate)\n",
    "        \n",
    "        Lr = LogisticRegression(penalty = 'l1', C = alpha_list[p], solver = 'liblinear', max_iter = 1000)\n",
    "\n",
    "        L1_model = OneVsRestClassifier(Lr)\n",
    "        L1_model.fit(X_train_new, Y_train_new_le)\n",
    "        L1_model.predict(X_validate)\n",
    "        \n",
    "        from sklearn.metrics import accuracy_score as acc\n",
    "        from sklearn.metrics import precision_score as pr\n",
    "        from sklearn.metrics import confusion_matrix as cm\n",
    "        \n",
    "        #print(\"Accuracy Score is:\",acc((Y_validate_le), Series(L1_model.predict(X_validate))))\n",
    "        \n",
    "        validation_accuracy = acc((Y_validate_le), Series(L1_model.predict(X_validate)))\n",
    "        validation_accuracy_score_model.append(validation_accuracy)\n",
    "        \n",
    "        training_accuracy = acc((Y_train_new_le), Series(L1_model.predict(X_train_new)))\n",
    "        training_accuracy_score_model.append(training_accuracy)\n",
    "        \n",
    "    print(\"Validation Accuracy Scores for Model:\",p, \"\\n\",validation_accuracy_score_model , \"\\n\")\n",
    "    validation_accuracy_matrix = pd.concat([validation_accuracy_matrix, DataFrame(validation_accuracy_score_model, columns = [\"Model%s\" % (p)])],  axis=1)\n",
    "    \n",
    "    print(\"Training Scores for Model:\",p, \"\\n\",training_accuracy_score_model , \"\\n\")\n",
    "    training_accuracy_matrix = pd.concat([training_accuracy_matrix, DataFrame(training_accuracy_score_model, columns = [\"Model%s\" % (p)])],  axis=1)\n",
    "    \n",
    "print((validation_accuracy_matrix),\"\\n\")\n",
    "print(\"Mean Validation Accuracy of Models:\\n\",validation_accuracy_matrix.mean(),\"\\n\")\n",
    "\n",
    "print((training_accuracy_matrix),\"\\n\")\n",
    "print(\"Mean Training Accuracy of Models:\\n\",training_accuracy_matrix.mean(),\"\\n\")\n",
    "\n",
    "#Overall Accuracy Matrix = Validation Accuracy Matrix + Training Accuracy Matrix\n",
    "\n",
    "overall_accuracy_matrix = validation_accuracy_matrix + training_accuracy_matrix\n",
    "print(\"Overall Training Accuracy of Models:\\n\",overall_accuracy_matrix.mean(),\"\\n\")\n",
    "\n",
    "print(\"Model with highest Overall accuracy score = \",overall_accuracy_matrix.mean().max(), \" is:\",overall_accuracy_matrix.mean().idxmax(),\n",
    "     \"\\nAnd It has Alpha value =\",alpha_list[best_alpha_index])\n",
    "\n",
    "print(\"final alpha:\",final_alpha)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cb8b063898>,\n",
       " <matplotlib.lines.Line2D at 0x1cb8b063978>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the Average Validation and Average Trainin Performance of models on a plot:\n",
    "\n",
    "overall_accuracy_df = pd.concat([validation_accuracy_matrix.mean(), training_accuracy_matrix.mean()], axis =1)\n",
    "overall_accuracy_df.head()\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(overall_accuracy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we can see from above plot, since on training data the accuray is 100% in all models,its hard to comment a little\n",
    "# but model 1,3,4 have better performance on validation set and models 8,9,10 have lower performance on validation dataset. So\n",
    "# Models 8,9,10 underfit since they have good accuracy on training but lower on validation.\n",
    "# But all models do overfit to a certain extent as trainin accuracy is max possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with Final Labmda:  33333\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[ -0.63878931]\n",
      " [ -0.09829861]\n",
      " [ -1.57151783]\n",
      " [ -2.06672666]\n",
      " [ -0.3873351 ]\n",
      " [  0.21389588]\n",
      " [ -1.04515141]\n",
      " [ -0.73345112]\n",
      " [-14.2232737 ]\n",
      " [ -4.50440955]] \n",
      "\n",
      "Accuracy =  0.8134920634920635             \n",
      "Confusion Matrix = \n",
      " [[82  1  2  0  0  1  0  1  2  0]\n",
      " [ 0 74  1  0  0  0  0  0  2  0]\n",
      " [ 1  3 63  2  1  1  0  2  8  2]\n",
      " [ 1  1  6 59  1  8  0  0  4  2]\n",
      " [ 0  0  4  0 59  2  2  1  3  7]\n",
      " [ 2  1  0  4  2 45  2  1  8  0]\n",
      " [ 0  0  1  0  2  0 67  0  1  0]\n",
      " [ 0  0  2  1  1  1  0 62  1  6]\n",
      " [ 1  3  2  1  0  5  1  1 40  3]\n",
      " [ 1  0  0  3  6  0  0  5  1 64]]\n",
      "Model Accuracy on training Data: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Re-training the best model:\n",
    "\n",
    "print(\"Model with Final Labmda: \", final_alpha)\n",
    "\n",
    "Lr = LogisticRegression(penalty = 'l1', C = final_alpha, solver = 'liblinear', max_iter = 1000)\n",
    "L1_model = OneVsRestClassifier(Lr)\n",
    "L1_model.fit(X_train, Y_train)\n",
    "L1_model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"\\n\",L1_model.coef_), print(\"\\n\",L1_model.intercept_,\"\\n\")\n",
    "\n",
    "accuracy = acc((Y_test), Series(L1_model.predict(X_test)))\n",
    "#precision = pr((Y_test), Series(L1_model.predict(X_test)))\n",
    "#recall = recall_score((Y_test), Series(L1_model.predict(X_test)))\n",
    "\n",
    "confusion_m = confusion_matrix((Y_test), Series(L1_model.predict(X_test)))\n",
    "\n",
    "print(\"Accuracy = \",accuracy, \"            \\nConfusion Matrix = \\n\",confusion_m)\n",
    "\n",
    "print(\"Model Accuracy on training Data:\" , acc((Y_train), Series(L1_model.predict(X_train))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2.2 Question 3\n",
    "\n",
    "#There is slight overfitting since model accuracy is very high on training data and avg on trainin data. \n",
    "#We need to make the model more generalised to work on general unseen datasets. \n",
    "#There is definiteve overfitting if we use this model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
